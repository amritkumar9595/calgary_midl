{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import data.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "import cv2 as  cv\n",
    "from models.models import dAUTOMAP, GeneralisedIFT2Layer\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "# from train_vs0 import build_model\n",
    "from models.models import _NetG \n",
    "loss_L1 = nn.L1Loss()\n",
    "loss_L2 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'center_fractions':[0.08],'accelerations':[4],'challenge':'singlecoil',\n",
    "       'data_path':Path('/media/student1/RemovableVolume/calgary/'),\n",
    "        \n",
    "       'resolution':170,\n",
    "       'sample_rate':0.1,\n",
    "       'batch_size':1,\n",
    "        'device':'cuda',\n",
    "        'data_parallel':False,\n",
    "        'num_chans':32,\n",
    "        'num_pools':4,\n",
    "        'drop_prob':0,\n",
    "        'acceleration':5,\n",
    "        'num_train':155,\n",
    "        'dropout':0,\n",
    "       }\n",
    "# d_named = namedtuple(\"Employee\", d.keys())(*d.values())\n",
    "args = namedtuple('args',args.keys())(*args.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_wise_ifft(zero_filled_kspace):\n",
    "    \"\"\"\n",
    "    Computes the iFFT across channels of multi-channel k-space data. The input is expected to be a complex numpy array.\n",
    "    \"\"\"\n",
    "    return np.fft.ifft2(zero_filled_kspace, axes = (1,2))\n",
    "    \n",
    "    \n",
    "\n",
    "def sum_of_squares(img_channels):\n",
    "    \"\"\"\n",
    "    Combines complex channels with square root sum of squares. The channels are the last dimension (i.e., -1) of the input array.\n",
    "    \"\"\"\n",
    "    return np.sqrt((np.abs(img_channels)**2).sum(axis = -1))\n",
    "    return sos    \n",
    "\n",
    "def zero_filled_reconstruction(zero_filled_kspace):\n",
    "    \"\"\"\n",
    "    Zero-filled reconstruction of multi-channel MR images. The input is the zero-filled k-space. The channels\n",
    "    are the last dimension of the array. The input may be either complex-valued or alternate between real and imaginary channels \n",
    "    in the last array dimension.\n",
    "    \"\"\"\n",
    "    if not np.iscomplexobj(zero_filled_kspace):\n",
    "        zero_filled_kspace = zero_filled_kspace[:,:,:,::2] + 1j*zero_filled_kspace[:,:,:,1::2] #convert real-imag to complex data\n",
    "    \n",
    "    return sum_of_squares(channel_wise_ifft(zero_filled_kspace)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions on VS-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file='/media/student1/RemovableVolume/calgary/12_channels_218_180/Val/e16972s3_P31232.7.80.h5'\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "            sens = data['sensitivity'][()]\n",
    "# ksp_np = np.expand_dims(ksp, axis=0)\n",
    "# print(\"ksp\",ksp_np.shape)\n",
    "            \n",
    "# img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "# img_gt_np.shape\n",
    "# img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "# print(img_gt_np.shape)\n",
    "# print(img_gt_np.min(),img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_t = T.to_tensor(sens)\n",
    "\n",
    "ksp_t = T.to_tensor(ksp)\n",
    "ksp_t = ksp_t.permute(2,0,1,3)\n",
    "img_gt = T.ifft2(ksp_t)\n",
    "img_gt_sens = T.combine_all_coils(img_gt , sens_t)\n",
    "\n",
    "img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "\n",
    "sp_r5 = np.load(\"/media/student1/NewVolume/MR_Reconstruction/midl/MC-MRRec-challenge/Data/poisson_sampling/R5_218x180.npy\")\n",
    "img_gt_sens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randint = random.randint(0,99)                   #to get a random mask everytime ! \n",
    "mask = sp_r5[randint]\n",
    "mask = torch.from_numpy(mask)\n",
    "mask = (torch.stack((mask,mask),dim=-1)).float()\n",
    "\n",
    "ksp_us = torch.where(mask == 0, torch.Tensor([0]), ksp_t)\n",
    "\n",
    "img_us = T.ifft2(ksp_us)\n",
    "img_us_sens = T.combine_all_coils(img_us , sens_t)\n",
    "\n",
    "ksp_us_np = ksp_us.numpy()\n",
    "ksp_us_cmplx = ksp_us_np[:,:,:,0] + 1j*ksp_us_np[:,:,:,1]\n",
    "ksp_us_cmplx = ksp_us_cmplx.transpose(1,2,0)\n",
    "\n",
    "img_us_np = T.zero_filled_reconstruction(ksp_us_cmplx)\n",
    "\n",
    "pha_gt = T.phase(img_gt_sens)\n",
    "pha_us = T.phase(img_us_sens) \n",
    "\n",
    "pha_gt = pha_gt + 3.1415927410125732\n",
    "pha_us = pha_us + 3.1415927410125732\n",
    "\n",
    "mag_gt = T.complex_abs(img_gt_sens)\n",
    "mag_us = T.complex_abs(img_us_sens)\n",
    "\n",
    "mag_gt_pad = T.pad(mag_gt,[256,256] )\n",
    "mag_us_pad = T.pad(mag_us,[256,256] )\n",
    "\n",
    "pha_gt_pad = T.pad(pha_gt,[256,256] )\n",
    "pha_us_pad = T.pad(pha_us,[256,256] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxi_sens = img_us_sens.max().cuda()\n",
    "# maxi_np = img_us_np.max()\n",
    "\n",
    "# ksp_us = ksp_us.unsqueeze(0).cuda()\n",
    "# ksp_t = ksp_t.unsqueeze(0).cuda()\n",
    "# img_gt_sens = img_gt_sens.unsqueeze(0).cuda()\n",
    " \n",
    "# img_gt_np = img_gt_np.unsqueeze(0).unsqueeze(0).cuda()\n",
    "# sens_t = sens_t.unsqueeze(0).cuda() \n",
    "# mask = mask.unsqueeze(0).cuda() \n",
    "# img_us_sens = img_us_sens.unsqueeze(0).cuda()\n",
    "# img_us_np = img_us_np.unsqueeze(0).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = img_us_sens.max().cuda()\n",
    "ksp_us = ksp_us.unsqueeze(0).cuda()/img_us_sens.max()\n",
    "ksp_t = ksp_t.unsqueeze(0).cuda()/img_us_sens.max() \n",
    "img_gt_sens = img_gt_sens.unsqueeze(0).cuda()/img_us_sens.max() \n",
    " \n",
    "img_gt_np = img_gt_np.unsqueeze(0).unsqueeze(0).cuda()/img_us_sens.max() \n",
    "sens_t = sens_t.unsqueeze(0).cuda() \n",
    "mask = mask.unsqueeze(0).cuda() \n",
    "img_us_sens = img_us_sens.unsqueeze(0).cuda()/img_us_sens.max()\n",
    "img_us_np = img_us_np.unsqueeze(0).unsqueeze(0).cuda()/img_us_sens.max()\n",
    "# fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ksp_us=\",ksp_us.shape)\n",
    "print(\"ksp_t = \",ksp_t.shape)\n",
    "print(\"img_us_sens\",img_us_sens.shape)\n",
    "print(\"img_gt_sens\",img_gt_sens.shape)\n",
    "print(\"img_us_np\",img_us_np.shape)\n",
    "print(\"img_gt_np\",img_gt_np.shape)\n",
    "print(\"sens_t\",sens_t.shape)\n",
    "print(\"mask\",mask.shape)\n",
    "# print(\"max\",maxi)\n",
    "# print(\"fname=\",fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_file = '/media/student1/NewVolume/MR_Reconstruction/experiments/chal_exp/active_learning/12_channel/acc_5x/best_vs_model.pt'\n",
    "model_vs , model_lo = build_model(args)\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "args = checkpoint['args']\n",
    "model_vs.load_state_dict(checkpoint['model_vs'])\n",
    "model_lo.load_state_dict(checkpoint['model_lo'])\n",
    "\n",
    "checkpoint_file = '/media/student1/NewVolume/MR_Reconstruction/experiments/chal_exp/active_learning/12_channel/acc_5x/best_dun_model.pt'\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model_dun =  _NetG().cuda()\n",
    "model_dun.load_state_dict(checkpoint['model_dun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vs,out_feat = model_vs(img_us_sens,ksp_us,sens_t,mask)\n",
    "out_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recons_max = \",out_vs.max() , \"gt_max\",img_gt_sens.max())\n",
    "out_lo = model_lo(out_feat[:-1])\n",
    "# l = F.mse_loss (out_vs,img_gt_sens)\n",
    "l2_us = loss_L2(img_us_sens,img_gt_sens)\n",
    "l2 = loss_L2(out_vs,img_gt_sens)\n",
    "\n",
    "# print(\"predicted loss = \",out_lo.item())\n",
    "print(\"actual loss=\",l2.item())\n",
    "print(\"US image loss\",l2_us.item())\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us_sens[0,:,:,0].detach().cpu()**2 + img_us_sens[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(img_gt_sens[0,:,:,0].detach().cpu()**2 + img_gt_sens[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt_sens - out_vs)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow((torch.sqrt(error[0,:,:,0].detach().cpu()**2 + error[0,:,:,1].detach().cpu()**2)),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dun = T.inp_to_dun(out_vs).float().to(args.device)\n",
    "out_dun = model_dun(inp_dun)\n",
    "out_dun.shape , img_gt_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "l2 = loss_L2(out_dun,img_gt_np.float())\n",
    "l2_us = loss_L2(inp_dun,img_gt_np.float())\n",
    "\n",
    "print(\"actual_loss = \",l2.item())\n",
    "print(\"input_loss=\",l2_us.item())\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(out_dun[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img_gt_np[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt_np.float() - out_dun.float())\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(error[0,0,:,:].detach().cpu(),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructions 32 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file='/media/student1/RemovableVolume/calgary/32_channels_218_180/Train/e16458s3_P33280.7.100.h5'\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "            sens = data['sensitivity'][()]\n",
    "# ksp_np = np.expand_dims(ksp, axis=0)\n",
    "# print(\"ksp\",ksp_np.shape)\n",
    "            \n",
    "# img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "# img_gt_np.shape\n",
    "# img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "# print(img_gt_np.shape)\n",
    "# print(img_gt_np.min(),img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_t = T.to_tensor(sens)\n",
    "\n",
    "ksp_t = T.to_tensor(ksp)\n",
    "ksp_t = ksp_t.permute(2,0,1,3)\n",
    "img_gt = T.ifft2(ksp_t)\n",
    "img_gt_sens = T.combine_all_coils(img_gt , sens_t)\n",
    "\n",
    "img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "\n",
    "sp_r5 = np.load(\"/media/student1/NewVolume/MR_Reconstruction/midl/MC-MRRec-challenge/Data/poisson_sampling/R5_218x180.npy\")\n",
    "img_gt_sens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randint = random.randint(0,99)                   #to get a random mask everytime ! \n",
    "mask = sp_r5[randint]\n",
    "mask = torch.from_numpy(mask)\n",
    "mask = (torch.stack((mask,mask),dim=-1)).float()\n",
    "\n",
    "ksp_us = torch.where(mask == 0, torch.Tensor([0]), ksp_t)\n",
    "\n",
    "img_us = T.ifft2(ksp_us)\n",
    "img_us_sens = T.combine_all_coils(img_us , sens_t)\n",
    "\n",
    "ksp_us_np = ksp_us.numpy()\n",
    "ksp_us_cmplx = ksp_us_np[:,:,:,0] + 1j*ksp_us_np[:,:,:,1]\n",
    "ksp_us_cmplx = ksp_us_cmplx.transpose(1,2,0)\n",
    "\n",
    "img_us_np = T.zero_filled_reconstruction(ksp_us_cmplx)\n",
    "\n",
    "pha_gt = T.phase(img_gt_sens)\n",
    "pha_us = T.phase(img_us_sens) \n",
    "\n",
    "pha_gt = pha_gt + 3.1415927410125732\n",
    "pha_us = pha_us + 3.1415927410125732\n",
    "\n",
    "mag_gt = T.complex_abs(img_gt_sens)\n",
    "mag_us = T.complex_abs(img_us_sens)\n",
    "\n",
    "mag_gt_pad = T.pad(mag_gt,[256,256] )\n",
    "mag_us_pad = T.pad(mag_us,[256,256] )\n",
    "\n",
    "pha_gt_pad = T.pad(pha_gt,[256,256] )\n",
    "pha_us_pad = T.pad(pha_us,[256,256] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = img_us_sens.max().cuda()\n",
    "ksp_us = ksp_us.unsqueeze(0).cuda()/img_us_sens.max()\n",
    "ksp_t = ksp_t.unsqueeze(0).cuda()/img_us_sens.max() \n",
    "img_gt_sens = img_gt_sens.unsqueeze(0).cuda()/img_us_sens.max() \n",
    " \n",
    "img_gt_np = img_gt_np.unsqueeze(0).unsqueeze(0).cuda()/img_us_np.max() \n",
    "sens_t = sens_t.unsqueeze(0).cuda() \n",
    "mask = mask.unsqueeze(0).cuda() \n",
    "img_us_sens = img_us_sens.unsqueeze(0).cuda()/img_us_sens.max()\n",
    "img_us_np = img_us_np.unsqueeze(0).unsqueeze(0).cuda()/img_us_np.max()\n",
    "# fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ksp_us=\",ksp_us.shape)\n",
    "print(\"ksp_t = \",ksp_t.shape)\n",
    "print(\"img_us_sens\",img_us_sens.shape)\n",
    "print(\"img_gt_sens\",img_gt_sens.shape)\n",
    "print(\"img_us_np\",img_us_np.shape)\n",
    "print(\"img_gt_np\",img_gt_np.shape)\n",
    "print(\"sens_t\",sens_t.shape)\n",
    "print(\"mask\",mask.shape)\n",
    "print(\"max\",maxi)\n",
    "# print(\"fname=\",fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = '/media/student1/NewVolume/MR_Reconstruction/experiments/chal_exp/active_learning/12_channel/acc_5x/best_vs_model.pt'\n",
    "model_vs , model_lo = build_model(args)\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "args = checkpoint['args']\n",
    "model_vs.load_state_dict(checkpoint['model_vs'])\n",
    "model_lo.load_state_dict(checkpoint['model_lo'])\n",
    "\n",
    "checkpoint_file = '/media/student1/NewVolume/MR_Reconstruction/experiments/chal_exp/active_learning/12_channel/acc_5x/best_dun_model.pt'\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model_dun =  _NetG().cuda()\n",
    "model_dun.load_state_dict(checkpoint['model_dun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vs,out_feat = model_vs(img_us_sens,ksp_us,sens_t,mask)\n",
    "out_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recons_max = \",out_vs.max() , \"gt_max\",img_gt_sens.max())\n",
    "out_lo = model_lo(out_feat[:-1])\n",
    "# l = F.mse_loss (out_vs,img_gt_sens,)\n",
    "\n",
    "l2_us = loss_L2(img_us_sens,img_gt_sens)\n",
    "l2 = loss_L2(out_vs,img_gt_sens)\n",
    "\n",
    "# print(\"predicted loss = \",out_lo.item())\n",
    "print(\"actual loss=\",l2.item())\n",
    "print(\"US image loss\",l2_us.item())\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us_sens[0,:,:,0].detach().cpu()**2 + img_us_sens[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(img_gt_sens[0,:,:,0].detach().cpu()**2 + img_gt_sens[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt_sens - out_vs)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow((torch.sqrt(error[0,:,:,0].detach().cpu()**2 + error[0,:,:,1].detach().cpu()**2)),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dun = T.inp_to_dun(out_vs).float().to(args.device)\n",
    "out_dun = model_dun(inp_dun)\n",
    "out_dun.shape , img_gt_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "l2 = loss_L2(out_dun,img_gt_np.float())\n",
    "print(\"actual_loss = \",l2.item())\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(out_dun[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img_gt_np[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt_np.float() - out_dun.float())\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(error[0,0,:,:].detach().cpu(),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(1,1)\n",
    "y=torch.randn(1,1)\n",
    "loss1 = F.mse_loss(x,y)\n",
    "loss2 = F.mse_loss(x,loss1.unsqueeze(0).unsqueeze(0))\n",
    "loss3 = F.mse_loss(x,loss1)\n",
    "loss2,loss3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/media/student1/RemovableVolume/calgary/Val/'\n",
    "# /media/student1/RemovableVolume/calgary_new/sens/test_12_channel\n",
    "\n",
    "dst = '/media/student1/RemovableVolume/calgary/Train_218_180/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=os.listdir(src)\n",
    "len(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=os.listdir(src)\n",
    "l2=os.listdir(dst)\n",
    "print(l2)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(items):\n",
    "#     print(\"item=\",item)\n",
    "    file = str(src)+str(item)\n",
    "    with h5py.File(file, 'r') as data:\n",
    "    # print(\"opening ksp\")\n",
    "        ksp = data['kspace'][()]\n",
    "        ksp_np = np.expand_dims(ksp, axis=0)\n",
    "        if(ksp_np.shape[2]==180):\n",
    "            from shutil import copyfile\n",
    "            src_f = src + item\n",
    "            dst_f = dst + item\n",
    "            copyfile(src_f, dst_f)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/media/student1/RemovableVolume/calgary/Train/e14140s3_P52224.7.50.h5'\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "ksp_np = np.expand_dims(ksp, axis=0)\n",
    "print(\"ksp\",ksp_np.shape)\n",
    "#             sens = data['sensitivity'][()]\n",
    "# img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "# img_gt_np.shape\n",
    "img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "print(img_gt_np.shape)\n",
    "print(img_gt_np.min(),img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_np.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32 channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/media/student1/RemovableVolume/calgary/calgary_32_additional_data/Train_218_180/e16461s3_P59904.7.190.h5'\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "ksp_np = np.expand_dims(ksp, axis=0)\n",
    "print(\"ksp\",ksp_np.shape)\n",
    "#             sens = data['sensitivity'][()]\n",
    "# img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "# img_gt_np.shape\n",
    "img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "print(img_gt_np.shape)\n",
    "print(img_gt_np.min(),img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_r5 = np.load(\"/media/student1/NewVolume/MR_Reconstruction/midl/MC-MRRec-challenge/Data/poisson_sampling/R5_218x180.npy\")\n",
    "sample_kspace_r5 = ksp.copy()\n",
    "sample_kspace_r5[~sp_r5[0],:] = 0\n",
    "sample_kspace_r5.shape\n",
    "sample_rec_train_r5 = np.fft.ifft2(sample_kspace_r5,axes = (0,1))\n",
    "sos2 = sum_of_squares(sample_rec_train_r5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(2,2,1)\n",
    "# plt.imshow(np.sqrt(img_gt_sens[:,:,0]**2 + img_gt_sens[:,:,1]**2),cmap='gray')\n",
    "plt.imshow(sos2,cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img_gt_np[0],cmap='gray')\n",
    "plt.colorbar()\n",
    "print(\"img_us\",sos2.min(),sos2.max())\n",
    "print(\"img_gt\",img_gt_np.min(),img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 10\n",
    "indices = list(range(NUM_TRAIN))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking predictions on 32 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcsv = '/media/student1/RemovableVolume/calgary/Recons/active_learning/32_channel/acc_5x/VS-NET/loss_pred.csv'\n",
    "df = pd.read_csv(fcsv)\n",
    "result  = df.sort_values(by='pred_loss',ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = 'e16509s3_P53248.7.187.h5'\n",
    "plt.figure(figsize=(24,24))\n",
    "\n",
    "file='/media/student1/RemovableVolume/calgary/32_channels_218_180/Val/'+ f\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "ksp_np = np.expand_dims(ksp, axis=0)\n",
    "img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "print(\"img_gt\",img_gt_np.shape)\n",
    "# print(img_gt_np.min(),img_gt_np.max())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img_gt_np[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "recon_file = \"/media/student1/RemovableVolume/calgary/Recons/active_learning/32_channel/acc_5x/VS-NET/\" + f\n",
    "hf_out = h5py.File(recon_file)\n",
    "recons = hf_out['Recons'][()]\n",
    "print(\"recons\",recons.shape)\n",
    "plt.imshow(recons[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3)\n",
    "error = np.abs(recons[0,:,:] -img_gt_np[0,:,:])\n",
    "loss = F.mse_loss(torch.from_numpy(recons).float(),torch.from_numpy(img_gt_np).float())\n",
    "print(\"loss=\",loss)\n",
    "plt.imshow(error,cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'e16509s3_P53248.7.60.h5'\n",
    "plt.figure(figsize=(24,24))\n",
    "\n",
    "file='/media/student1/RemovableVolume/calgary/32_channels_218_180/Val/' + f\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "ksp_np = np.expand_dims(ksp, axis=0)\n",
    "img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "print(\"img_gt\",img_gt_np.shape)\n",
    "# print(img_gt_np.min(),img_gt_np.max())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img_gt_np[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "recon_file = \"/media/student1/RemovableVolume/calgary/Recons/active_learning/32_channel/acc_5x/VS-NET/\" + f \n",
    "hf_out = h5py.File(recon_file)\n",
    "recons = hf_out['Recons'][()]\n",
    "print(\"recons\",recons.shape)\n",
    "plt.imshow(recons[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3)\n",
    "error = np.abs(recons[0,:,:] -img_gt_np[0,:,:])\n",
    "loss = F.mse_loss(torch.from_numpy(recons).float(),torch.from_numpy(img_gt_np).float())\n",
    "print(\"loss=\",loss)\n",
    "plt.imshow(error,cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'e16509s3_P53248.7.89.h5'\n",
    "plt.figure(figsize=(24,24))\n",
    "\n",
    "file='/media/student1/RemovableVolume/calgary/32_channels_218_180/Val/' + f\n",
    "with h5py.File(file, 'r') as data:\n",
    "        # print(\"opening ksp\")\n",
    "            ksp = data['kspace'][()]\n",
    "ksp_np = np.expand_dims(ksp, axis=0)\n",
    "img_gt_np = zero_filled_reconstruction(ksp_np)\n",
    "print(\"img_gt\",img_gt_np.shape)\n",
    "# print(img_gt_np.min(),img_gt_np.max())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img_gt_np[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "recon_file = \"/media/student1/RemovableVolume/calgary/Recons/active_learning/32_channel/acc_5x/VS-NET/\" + f\n",
    "hf_out = h5py.File(recon_file)\n",
    "recons = hf_out['Recons'][()]\n",
    "print(\"recons\",recons.shape)\n",
    "plt.imshow(recons[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3)\n",
    "error = np.abs(recons[0,:,:] -img_gt_np[0,:,:])\n",
    "loss = F.mse_loss(torch.from_numpy(recons).float(),torch.from_numpy(img_gt_np).float())\n",
    "print(\"loss=\",loss)\n",
    "plt.imshow(error,cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_kspace_r5 = ksp.copy()\n",
    "sample_kspace_r5[~sp_r5[0],:] = 0\n",
    "sample_kspace_r5.shape\n",
    "sample_rec_train_r5 = np.fft.ifft2(sample_kspace_r5,axes = (0,1))\n",
    "sos2 = sum_of_squares(sample_rec_train_r5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5,6]\n",
    "b=[0,1]\n",
    "a = np.array(a)\n",
    "a = np.delete(a,(0,3,5))\n",
    "a=list(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arg = np.argsort(a)\n",
    "arg[::-1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty =[]\n",
    "uncertainty.append(10)\n",
    "uncertainty.append(5)\n",
    "uncertainty.append(15)\n",
    "uncertainty.append(2)\n",
    "uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = np.argsort(uncertainty)\n",
    "arg = arg[::-1]\n",
    "arg = list(arg)\n",
    "arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "index_set= list(range(20)) \n",
    "list(torch.tensor(subset)[arg][:3].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dautomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dautomap(args):\n",
    "    # checkpoint = torch.load(checkpoint_file)\n",
    "    # args = checkpoint['args']\n",
    "\n",
    "#     patch_size = args.resolution\n",
    "    model_params = {\n",
    "      'input_shape': (64, 218, 180),\n",
    "      'output_shape': (64, 218, 180),\n",
    "      'tfx_params': {\n",
    "        'nrow': 218,\n",
    "        'ncol': 180,\n",
    "        'nch_in': 64,\n",
    "        'kernel_size': 1,\n",
    "        'nl': None,\n",
    "        'init_fourier': False,\n",
    "        'init':None,  # 'kaiming_normal_',  #'xavier_uniform_',\n",
    "        'bias': False, #True,\n",
    "        'share_tfxs': False,\n",
    "        'learnable': True\n",
    "      },\n",
    "      'tfx_params2': {\n",
    "        'nrow': 218,\n",
    "        'ncol': 180,\n",
    "        'nch_in': 64,\n",
    "        'kernel_size': 1,\n",
    "        'nl': 'relu',\n",
    "        'init_fourier': False,\n",
    "        'init': 'kaiming_normal_', # 'xavier_uniform_',\n",
    "        'bias':True,\n",
    "        'share_tfxs': False,\n",
    "        'learnable': True\n",
    "      },\n",
    "      'depth': 2,\n",
    "      'nl':'relu'\n",
    "    }\n",
    "\n",
    "    model = dAUTOMAP(model_params['input_shape'],model_params['output_shape'],model_params['tfx_params'],model_params['tfx_params2']).to(args.device)\n",
    "\n",
    "    if args.data_parallel:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # model.load_state_dict(checkpoint['model'])\n",
    "    return model\n",
    "\n",
    "def multicoil_fourier_init(args,mdl):\n",
    "    mdl0 = GeneralisedIFT2Layer(218,180,2)\n",
    "    ncoils = 32 # FIXME: can come from args\n",
    "    n1 = 2*218\n",
    "    n3 = 2*180\n",
    "    for ii in range(ncoils):\n",
    "        d1 = ii*n1\n",
    "        d2 = ii*2\n",
    "        d3 = ii*n3\n",
    "        mdl.idft1.weight.data[d1:d1+n1,d2:d2+2,:,:]=mdl0.idft1.weight.data[:,:,:,:]\n",
    "        mdl.idft2.weight.data[d3:d3+n3,d2:d2+2,:,:]=mdl0.idft2.weight.data[:,:,:,:]\n",
    "\n",
    "def build_dautomap_model(args):\n",
    "    model = build_dautomap(args)\n",
    "    multicoil_fourier_init(args, model.domain_transform)  ## taking the domain _transform part only!!\n",
    "\n",
    "    return model.to(args.device)\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dautomap_model = build_dautomap_model(args)\n",
    "dautomap_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,64,218,180)\n",
    "y = dautomap_model.domain_transform(stacked_ksp_us.cuda())\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.sqrt(y[0,30,:,:].detach().cpu()**2 + y[0,31,:,:].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_coeff():\n",
    "    return 0.002, 0.005\n",
    "\n",
    "def perform(out_img_cmplx,ksp,sens,mask ):\n",
    "\n",
    "    x = T.complex_multiply(out_img_cmplx[...,0].unsqueeze(1), out_img_cmplx[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "\n",
    "    k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "    k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "\n",
    "    sr = 0.85\n",
    "    Nz = k_shift.shape[-2] \n",
    "    Nz_sampled = int(np.ceil(Nz*sr))\n",
    "    k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "\n",
    "    v = self.noise_lvl\n",
    "    if v is not None: # noisy case\n",
    "        # out = (1 - mask) * k + mask * (k + v * k0) / (1 + v)\n",
    "        out = (1 - mask) * k_shift + mask * (v * k_shift + (1 - v) * ksp) \n",
    "\n",
    "    else:\n",
    "\n",
    "        out = (1 - mask) * k_shift + mask * ksp\n",
    "\n",
    "\n",
    "    x = torch.ifft(out, 2, normalized=True)\n",
    "\n",
    "    Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "\n",
    "    Ss = T.complex_multiply(sens[...,0], sens[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "\n",
    "    return Sx, Ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(x_hat, gt, y, mask, device, strategy, batch_idx, epoch, phase, max_batch):  \n",
    "    print('strategy',strategy) \n",
    "    if strategy == 'unsup':\n",
    "        loss = final_loss(x_hat, y, mask, device)\n",
    "    elif strategy == 'sup':\n",
    "        loss = nn.MSELoss()(x_hat, gt)\n",
    "\n",
    "    # Trains supervised for 20 epochs, and only on first 1/10 of the dataset\n",
    "    # Trains unsupervised for rest of the epochs, and on 9/10 of the dataset\n",
    "    elif strategy == 'refine':\n",
    "        if phase == 'train' and epoch <= 100:\n",
    "            if batch_idx < max_batch // 2:\n",
    "                loss = nn.MSELoss()(x_hat, gt)\n",
    "                print('sup on batch_idx', str(batch_idx))\n",
    "            else:\n",
    "                loss = None\n",
    "                print('sup skipping batch_idx', str(batch_idx))\n",
    "        elif phase == 'train' and epoch > 100:\n",
    "            if batch_idx >= max_batch // 2:\n",
    "                loss = final_loss(x_hat, y, mask, device)\n",
    "                print('unsup on batch_idx', str(batch_idx))\n",
    "            else:\n",
    "                loss = None\n",
    "                print('unsup skipping batch_idx', str(batch_idx))\n",
    "        else:\n",
    "            loss = nn.MSELoss()(x_hat, gt)\n",
    "            print('validation in refine')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(x_hat, y, mask, device, reg_only=False):\n",
    "    w_coeff, tv_coeff = get_reg_coeff()\n",
    "\n",
    "    l1 = torch.nn.L1Loss(reduction='sum')\n",
    "    l2 = torch.nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    print(\"mask_before\",mask.shape)\n",
    "    mask_expand = mask  #.unsqueeze(2)\n",
    "    print(\"mask_after\",mask_expand.shape)\n",
    "    \n",
    "    # Data consistency term\n",
    "    x = T.complex_multiply(x_hat[...,0].unsqueeze(1), x_hat[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "    k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "    k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "#     Fx_hat = utils.fft(x_hat)\n",
    "    UFx_hat = Fx_hat * mask_expand\n",
    "    dc = l2(UFx_hat, y)\n",
    "\n",
    "    # Regularization\n",
    "    x_hat = x_hat.permute(0, 3, 1, 2)\n",
    "    tv = get_tv(x_hat)\n",
    "    wavelets = get_wavelets(x_hat, device)\n",
    "    l1_wavelet = l1(wavelets, torch.zeros_like(wavelets)) # we want L1 value by itself, not the error\n",
    " \n",
    "    reg = w_coeff*l1_wavelet + tv_coeff*tv\n",
    "\n",
    "    if reg_only:\n",
    "        loss = reg\n",
    "    else:\n",
    "        loss = dc + reg\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out_vs,img_us,ksp_us,sens,mask,maxi):\n",
    "    x = T.complex_multiply(out_vs[...,0].unsqueeze(1), out_vs[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "    k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "    k2 = k.clone()\n",
    "\n",
    "    k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "    sr = 0.85\n",
    "    Nz = k_shift.shape[-2] \n",
    "    Nz_sampled = int(np.ceil(Nz*sr))\n",
    "    k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "\n",
    "    sr = 0.85\n",
    "    Nz = k2.shape[-2] \n",
    "    Nz_sampled = int(np.ceil(Nz*sr))\n",
    "    k2[:,:,:,Nz_sampled:,:] = 0\n",
    "    \n",
    "#     out = (1 - mask) * k2 + mask * ksp_us\n",
    "#     x = torch.ifft(out, 2, normalized=True)\n",
    "#     Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "    \n",
    "    ksp_us_recons = torch.where(mask.squeeze(0) == 0, torch.Tensor([0]).cuda(), k_shift.squeeze(0))\n",
    "    img_us_recons = T.ifft2(ksp_us_recons)\n",
    "    img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "    \n",
    "#     print(\"img_us_sens_recons\",img_us_sens_recons.max())\n",
    "#     print(\"out_vs\",out_vs.max())\n",
    "#     out_vs = out_vs/maxi\n",
    "    img_us_sens_recons = img_us_sens_recons/maxi\n",
    "    l = F.mse_loss (img_us_sens_recons,img_us.squeeze(0))\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloading and training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_active import create_data_loaders, build_model\n",
    "\n",
    "\n",
    "# from models.models import cnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 155\n",
    "index_set = list(range(num_train)) \n",
    "train_loader, dev_loader,display_loader = create_data_loaders(args,index_set)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ksp_us,ksp_gt,img_us,img_gt,img_us_np,img_gt_np,sens,mask,maxi,_,_   in (train_loader):\n",
    "\n",
    "    break\n",
    "ksp_us = ksp_us.to(args.device)\n",
    "sens = sens.to(args.device)\n",
    "mask = mask.to(args.device)\n",
    "img_gt = img_gt.to(args.device)\n",
    "img_us = img_us.to(args.device)\n",
    "\n",
    "print('ksp',ksp_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dautomap(args):\n",
    "    # checkpoint = torch.load(checkpoint_file)\n",
    "    # args = checkpoint['args']\n",
    "\n",
    "#     patch_size = args.resolution\n",
    "    model_params = {\n",
    "      'input_shape': (64, 218, 180),\n",
    "      'output_shape': (64, 218, 180),\n",
    "      'tfx_params': {\n",
    "        'nrow': 218,\n",
    "        'ncol': 180,\n",
    "        'nch_in': 64,\n",
    "        'kernel_size': 1,\n",
    "        'nl': None,\n",
    "        'init_fourier': False,\n",
    "        'init':None,  # 'kaiming_normal_',  #'xavier_uniform_',\n",
    "        'bias': False, #True,\n",
    "        'share_tfxs': False,\n",
    "        'learnable': True\n",
    "      },\n",
    "      'tfx_params2': {\n",
    "        'nrow': 218,\n",
    "        'ncol': 180,\n",
    "        'nch_in': 64,\n",
    "        'kernel_size': 1,\n",
    "        'nl': 'relu',\n",
    "        'init_fourier': False,\n",
    "        'init': 'kaiming_normal_', # 'xavier_uniform_',\n",
    "        'bias':True,\n",
    "        'share_tfxs': False,\n",
    "        'learnable': True\n",
    "      },\n",
    "      'depth': 2,\n",
    "      'nl':'relu'\n",
    "    }\n",
    "\n",
    "    model = dAUTOMAP(model_params['input_shape'],model_params['output_shape'],model_params['tfx_params'],model_params['tfx_params2']).to(args.device)\n",
    "\n",
    "    if args.data_parallel:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # model.load_state_dict(checkpoint['model'])\n",
    "    return model\n",
    "\n",
    "def multicoil_fourier_init(args,mdl):\n",
    "    mdl0 = GeneralisedIFT2Layer(218,180,2)\n",
    "    ncoils = 32 # FIXME: can come from args\n",
    "    n1 = 2*218\n",
    "    n3 = 2*180\n",
    "    for ii in range(ncoils):\n",
    "        d1 = ii*n1\n",
    "        d2 = ii*2\n",
    "        d3 = ii*n3\n",
    "        mdl.idft1.weight.data[d1:d1+n1,d2:d2+2,:,:]=mdl0.idft1.weight.data[:,:,:,:]\n",
    "        mdl.idft2.weight.data[d3:d3+n3,d2:d2+2,:,:]=mdl0.idft2.weight.data[:,:,:,:]\n",
    "\n",
    "def build_dautomap_model(args):\n",
    "    model = build_dautomap(args)\n",
    "    multicoil_fourier_init(args, model.domain_transform)  ## taking the domain _transform part only!!\n",
    "\n",
    "    return model.to(args.device)\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_ksp(k):\n",
    "    stacked_ksp = []\n",
    "\n",
    "    for i in (range(32)):\n",
    "        stacked_ksp.append(k[0,i,:,:,0])\n",
    "        stacked_ksp.append(k[0,i,:,:,1])\n",
    "\n",
    "    stacked_ksp = torch.stack(stacked_ksp)\n",
    "    stacked_ksp = stacked_ksp.unsqueeze(0)\n",
    "    \n",
    "    return stacked_ksp  \n",
    "\n",
    "def stack_to_chans(inp):\n",
    "    ## converts tensor of shape(bs,30,320,320) to tensor of shape(bs,15,320,320,2)\n",
    "    ## useful for applying fft2 and ifft2 which demands last dim=2\n",
    "    \n",
    "    stack_1 = inp[:,list(range(0,64,2)),:,:]\n",
    "    stack_2 = inp[:,list(range(1,64,2)),:,:] \n",
    "    \n",
    "    stack_0 = torch.stack((stack_1,stack_2),dim = -1)\n",
    "\n",
    "    return stack_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "ans = stack_to_chans(stack_ksp(ksp_us))\n",
    "ans = torch.ifft(ans, 2, normalized=True)\n",
    "ans_img = T.combine_all_coils(ans.squeeze(0) , sens.squeeze(0)).unsqueeze(0)\n",
    "print(ans_img.shape)\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(ans_img[0,:,:,0].detach().cpu()**2 + ans_img[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "ans = stack_to_chans(stack_ksp(T.ifftshift(ksp_us, dim=(-2,-1))))\n",
    "ans = torch.ifft(ans, 2, normalized=True)\n",
    "ans_img = T.combine_all_coils(ans.squeeze(0) , sens.squeeze(0)).unsqueeze(0)\n",
    "print(ans_img.shape)\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(ans_img[0,:,:,0].detach().cpu()**2 + ans_img[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "# dautomap_model\n",
    "# x = torch.rand(1,64,218,180)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "y = dautomap_model(stack_ksp(k).cuda())\n",
    "print(y.shape)\n",
    "plt.imshow(torch.sqrt(y[0,62,:,:].detach().cpu()**2 + y[0,63,:,:].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "y = dautomap_model(stack_ksp(T.ifftshift(k, dim=(-2,-1))).cuda())\n",
    "print(y.shape)\n",
    "plt.imshow(torch.sqrt(y[0,62,:,:].detach().cpu()**2 + y[0,63,:,:].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "d = torch.ifft(k, 2, normalized=True)\n",
    "d.shape\n",
    "plt.imshow(torch.sqrt(d[0,16,:,:,0].detach().cpu()**2 + d[0,17,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "d = torch.ifft(T.ifftshift(k, dim=(-2,-1)), 2, normalized=True)\n",
    "d.shape\n",
    "plt.imshow(torch.sqrt(d[0,16,:,:,0].detach().cpu()**2 + d[0,17,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_vs and model_lo to be the trained on 12 channel data\n",
    "# will be added later\n",
    "# dautomap_model = build_dautomap_model(args)\n",
    "checkpoint_file = '/media/student1/NewVolume/MR_Reconstruction/experiments/chal_exp/active_learning/12_channel/acc_5x/best_vs_model.pt'\n",
    "model_vs , model_lo = build_model(args)\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "args = checkpoint['args']\n",
    "model_vs.load_state_dict(checkpoint['model_vs'])\n",
    "model_lo.load_state_dict(checkpoint['model_lo'])\n",
    "# optimizer1 = torch.optim.Adam(dautomap_model.parameters() , 0.001)\n",
    "optimizer2 = torch.optim.Adam(model_vs.parameters() , 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions before training on 32 channels \n",
    "out_vs,out_feat = model_vs(img_us,ksp_us,sens,mask)\n",
    "print(\"recons_max = \",out_vs.max() , \"gt_max\",img_gt.max())\n",
    "out_lo = model_lo(out_feat[:-1])\n",
    "l = F.mse_loss (out_vs,img_gt)\n",
    "\n",
    "print(\"predicted loss = \",out_lo.item())\n",
    "print(\"actual loss=\",l.item())\n",
    "\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us[0,:,:,0].detach().cpu()**2 + img_us[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(img_gt[0,:,:,0].detach().cpu()**2 + img_gt[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt - out_vs)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(torch.sqrt(error[0,:,:,0].detach().cpu()**2 + error[0,:,:,1].detach().cpu()**2),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(out_vs,img_us,ksp_us,sens,mask,maxi):\n",
    "#     x = T.complex_multiply(out_vs[...,0].unsqueeze(1), out_vs[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "#     y = T.complex_multiply(img_us[...,0].unsqueeze(1), img_us[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "#     k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "#     k2 = k.clone()\n",
    "\n",
    "#     k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "#     sr = 0.85\n",
    "#     Nz = k_shift.shape[-2] \n",
    "#     Nz_sampled = int(np.ceil(Nz*sr))\n",
    "#     k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "\n",
    "#     sr = 0.85\n",
    "#     Nz = k2.shape[-2] \n",
    "#     Nz_sampled = int(np.ceil(Nz*sr))\n",
    "#     k2[:,:,:,Nz_sampled:,:] = 0\n",
    "# #     \n",
    "# #     out = (1 - mask) * k2 + mask * ksp_us\n",
    "# #     x = torch.ifft(out, 2, normalized=True)\n",
    "# #     Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "    \n",
    "#     ksp_us_recons = torch.where(mask.squeeze(0) == 0, torch.Tensor([0]).cuda(), k_shift.squeeze(0))\n",
    "#     img_us_recons = T.ifft2(ksp_us_recons)\n",
    "#     img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "    \n",
    "# #     print(\"ksp_us_recons\",img_us_recons.shape)\n",
    "# #     print(\"y\",y.shape)\n",
    "# #     out_vs = out_vs/maxi\n",
    "   \n",
    "# #     l1 = F.mse_loss (ksp_us_recons ,ksp_us.squeeze(0) )\n",
    "    \n",
    "# #     img_us_sens_recons = img_us_sens_recons/maxi\n",
    "#     l2 = F.mse_loss (img_us_recons,y.squeeze(0))\n",
    "    \n",
    "#     return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(out_vs,img_us,ksp_us,sens,mask,maxi):\n",
    "    x = T.complex_multiply(out_vs[...,0].unsqueeze(1), out_vs[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "    y = T.complex_multiply(img_us[...,0].unsqueeze(1), img_us[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "    k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "    k2 = k.clone()\n",
    "\n",
    "    k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "    sr = 0.85\n",
    "    Nz = k_shift.shape[-2] \n",
    "    Nz_sampled = int(np.ceil(Nz*sr))\n",
    "    k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "\n",
    "    sr = 0.85\n",
    "    Nz = k2.shape[-2] \n",
    "    Nz_sampled = int(np.ceil(Nz*sr))\n",
    "    k2[:,:,:,Nz_sampled:,:] = 0\n",
    "    \n",
    "#     out = (1 - mask) * k2 + mask * ksp_us\n",
    "#     x = torch.ifft(out, 2, normalized=True)\n",
    "#     Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "    \n",
    "    ksp_us_recons = torch.where(mask.squeeze(0) == 0, torch.Tensor([0]).cuda(), k2.squeeze(0))\n",
    "    img_us_recons = T.ifft2(ksp_us_recons)\n",
    "    img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "    \n",
    "#     print(\"ksp_us_recons\",img_us_recons.shape)\n",
    "#     print(\"y\",y.shape)\n",
    "#     out_vs = out_vs/maxi\n",
    "   \n",
    "#     l1 = F.mse_loss (ksp_us_recons ,ksp_us.squeeze(0) )\n",
    "    \n",
    "#     img_us_sens_recons = img_us_sens_recons/maxi\n",
    "    l2 = F.mse_loss (img_us_sens_recons,img_us.squeeze(0))\n",
    "    \n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "losses_mse = []\n",
    "# pha_loss = []\n",
    "model_vs.train()\n",
    "# model_pha.train()\n",
    "for _ in tqdm(range(epochs)):\n",
    "    \n",
    "    loss_mse =  F.mse_loss (out_vs,img_gt)\n",
    "#     img = dautomap_model(stack_ksp(ksp_us).cuda())\n",
    "#     img2 = stack_to_chans(img)\n",
    "#     img3 = T.combine_all_coils(img2.squeeze(0) , sens.squeeze(0)).unsqueeze(0)\n",
    "#     print(\"ans_img\",img3.shape)\n",
    "    \n",
    "    \n",
    "    out_vs,out_feat = model_vs(img_us,ksp_us,sens,mask) \n",
    "    loss_mse = F.mse_loss(out_vs ,img_gt)\n",
    "    losses_mse.append(loss_mse.item())\n",
    "    \n",
    "    loss_cmplx = loss(out_vs.cuda(),img_us,ksp_us,sens,mask,maxi.float().cuda())\n",
    "    losses.append(loss_cmplx.item())\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    \n",
    "    loss_cmplx.backward()\n",
    "    \n",
    "#     optimizer1.step()\n",
    "    optimizer2.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us[0,:,:,0].detach().cpu()**2 + img_us[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(img_gt[0,:,:,0].detach().cpu()**2 + img_gt[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "# plt.imshow(img_gt_np[0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(torch.sqrt(img3[0,:,:,0].detach().cpu()**2 + img3[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "# plt.colorbar()\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(losses)\n",
    "plt.title('unsupervised loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(losses_mse)\n",
    "plt.title('loss between GT and recons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vs,_ = model_vs(img_us,ksp_us,sens,mask)\n",
    "print(\"recons_max = \",out_vs.max() , \"gt_max\",img_gt.max())\n",
    "l = F.mse_loss (out_vs,img_gt)\n",
    "print(\"actual loss=\",l.item())\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us[0,:,:,0].detach().cpu()**2 + img_us[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.sqrt(img_gt[0,:,:,0].detach().cpu()**2 + img_gt[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "error = torch.abs(img_gt - out_vs)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(torch.sqrt(error[0,:,:,0].detach().cpu()**2 + error[0,:,:,1].detach().cpu()**2),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens2 = torch.sqrt(sens[:,:,:,:,0]**2 + sens[:,:,:,:,1]**2)\n",
    "sens2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens3 = torch.sum(sens,1)\n",
    "sens3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens4 = torch.sqrt(sens3[0,:,:,0]**2 + sens3[0,:,:,1]**2)\n",
    "sens4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sens4.detach().cpu() > 0.8)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.complex_multiply(out_vs[...,0].unsqueeze(1), out_vs[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "y = T.complex_multiply(img_us[...,0].unsqueeze(1), img_us[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "z = T.complex_multiply(img_gt[...,0].unsqueeze(1), img_gt[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "  \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(torch.sqrt(x[0,slice,:,:,0].detach().cpu()**2 + x[0,slice,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(torch.sqrt(y[0,slice,:,:,0].detach().cpu()**2 + y[0,slice,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(torch.sqrt(sens[0,slice,:,:,0].detach().cpu()**2 + sens[0,slice,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "print(k.shape , k_shift.shape)\n",
    "sr = 0.85\n",
    "Nz = k_shift.shape[-2] \n",
    "Nz_sampled = int(np.ceil(Nz*sr))\n",
    "k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.log(torch.sqrt(k[0,slice,:,:,0].detach().cpu()**2 + k[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.log(torch.sqrt(k_shift[0,slice,:,:,0].detach().cpu()**2 + k_shift[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.log(torch.sqrt(ksp_us[0,slice,:,:,0].detach().cpu()**2 + ksp_us[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(torch.log(torch.sqrt(ksp_gt[0,slice,:,:,0].detach().cpu()**2 + ksp_gt[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_us_recons = torch.where(mask.squeeze(0) == 0, torch.Tensor([0]).cuda(), k_shift.squeeze(0))\n",
    "ksp_us_recons = ksp_us_recons.unsqueeze(0)\n",
    "\n",
    "img_us_recons = T.ifft2(ksp_us_recons)\n",
    "img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.log(torch.sqrt(ksp_us_recons[0,slice,:,:,0].detach().cpu()**2 + ksp_us_recons[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "img_us_recons = T.ifft2(ksp_us_recons)\n",
    "img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "\n",
    "# img_us_sens_recons = img_us_sens_recons/maxi.float().cuda()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow((torch.sqrt(img_us_recons[0,slice,:,:,0].detach().cpu()**2 + img_us_recons[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow((torch.sqrt(y[0,slice,:,:,0].detach().cpu()**2 + y[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow((torch.sqrt(z[0,slice,:,:,0].detach().cpu()**2 + z[0,slice,:,:,1].detach().cpu()**2)+ 1e-8),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# an experiment with fastmri dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vs,_ = model_vs(img_us,ksp_us,sens,mask)\n",
    "out_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us[0,:,:,0].detach().cpu()**2 + img_us[0,:,:,1].detach().cpu()**2))\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(out_vs[0,:,:,0].detach().cpu()**2 + out_vs[0,:,:,1].detach().cpu()**2))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.complex_multiply(out_vs[...,0].unsqueeze(1), out_vs[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "x.shape\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "k2 = k.clone()\n",
    "k.shape\n",
    "k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "k_shift.shape\n",
    "sr = 0.85\n",
    "Nz = k_shift.shape[-2] \n",
    "Nz_sampled = int(np.ceil(Nz*sr))\n",
    "k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "k_shift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 0.85\n",
    "Nz = k2.shape[-2] \n",
    "Nz_sampled = int(np.ceil(Nz*sr))\n",
    "k2[:,:,:,Nz_sampled:,:] = 0\n",
    "k2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.log(torch.sqrt(ksp_us[0,0,:,:,0].detach().cpu()**2 + ksp_us[0,0,:,:,1].detach().cpu()**2)+1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.log(torch.sqrt(k[0,0,:,:,0].detach().cpu()**2 + k[0,0,:,:,1].detach().cpu()**2)+1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(torch.log(torch.sqrt(k2[0,0,:,:,0].detach().cpu()**2 + k2[0,0,:,:,1].detach().cpu()**2)+1e-8),cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(torch.log(torch.sqrt(k_shift[0,0,:,:,0].detach().cpu()**2 + k_shift[0,0,:,:,1].detach().cpu()**2)+1e-8),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# out = (1 - mask) * k2 + mask * ksp_us\n",
    "x = torch.ifft(k_shift, 2, normalized=True)\n",
    "\n",
    "Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "Sx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(torch.sqrt(Sx[0,:,:,0].detach().cpu()**2 + Sx[0,:,:,1].detach().cpu()**2),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_us_recons = torch.where(mask.squeeze(0) == 0, torch.Tensor([0]).cuda(), k_shift.squeeze(0))\n",
    "img_us_recons = T.ifft2(ksp_us_recons)\n",
    "img_us_sens_recons = T.combine_all_coils(img_us_recons , sens.squeeze(0))\n",
    "img_us_sens_recons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(torch.sqrt(img_us[0,:,:,0].detach().cpu()**2 + img_us[0,:,:,1].detach().cpu()**2))\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(torch.sqrt(img_us_sens_recons[:,:,0].detach().cpu()**2+img_us_sens_recons[:,:,1].detach().cpu()**2),cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end-to-end net|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "    O. Ronneberger, P. Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "    for biomedical image segmentation. In International Conference on Medical\n",
    "    image computing and computer-assisted intervention, pages 234–241.\n",
    "    Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans: int,\n",
    "        out_chans: int,\n",
    "        chans: int = 32,\n",
    "        num_pool_layers: int = 4,\n",
    "        drop_prob: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input to the U-Net model.\n",
    "            out_chans: Number of channels in the output to the U-Net model.\n",
    "            chans: Number of output channels of the first convolution layer.\n",
    "            num_pool_layers: Number of down-sampling and up-sampling layers.\n",
    "            drop_prob: Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for _ in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers.append(ConvBlock(ch, ch * 2, drop_prob))\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch * 2, drop_prob)\n",
    "\n",
    "        self.up_conv = nn.ModuleList()\n",
    "        self.up_transpose_conv = nn.ModuleList()\n",
    "        for _ in range(num_pool_layers - 1):\n",
    "            self.up_transpose_conv.append(TransposeConvBlock(ch * 2, ch))\n",
    "            self.up_conv.append(ConvBlock(ch * 2, ch, drop_prob))\n",
    "            ch //= 2\n",
    "\n",
    "        self.up_transpose_conv.append(TransposeConvBlock(ch * 2, ch))\n",
    "        self.up_conv.append(\n",
    "            nn.Sequential(\n",
    "                ConvBlock(ch * 2, ch, drop_prob),\n",
    "                nn.Conv2d(ch, self.out_chans, kernel_size=1, stride=1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H, W)`.\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = image\n",
    "\n",
    "        # apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.avg_pool2d(output, kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # apply up-sampling layers\n",
    "        for transpose_conv, conv in zip(self.up_transpose_conv, self.up_conv):\n",
    "            downsample_layer = stack.pop()\n",
    "            output = transpose_conv(output)\n",
    "\n",
    "            # reflect pad on the right/botton if needed to handle odd input dimensions\n",
    "            padding = [0, 0, 0, 0]\n",
    "            if output.shape[-1] != downsample_layer.shape[-1]:\n",
    "                padding[1] = 1  # padding right\n",
    "            if output.shape[-2] != downsample_layer.shape[-2]:\n",
    "                padding[3] = 1  # padding bottom\n",
    "            if torch.sum(torch.tensor(padding)) != 0:\n",
    "                output = F.pad(output, padding, \"reflect\")\n",
    "\n",
    "            output = torch.cat([output, downsample_layer], dim=1)\n",
    "            output = conv(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, LeakyReLU activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans: int, out_chans: int, drop_prob: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input.\n",
    "            out_chans: Number of channels in the output.\n",
    "            drop_prob: Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H, W)`.\n",
    "        \"\"\"\n",
    "        return self.layers(image)\n",
    "\n",
    "\n",
    "class TransposeConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transpose Convolutional Block that consists of one convolution transpose\n",
    "    layers followed by instance normalization and LeakyReLU activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans: int, out_chans: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input.\n",
    "            out_chans: Number of channels in the output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_chans, out_chans, kernel_size=2, stride=2, bias=False\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H*2, W*2)`.\n",
    "        \"\"\"\n",
    "        return self.layers(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormUnet(nn.Module):\n",
    "    def __init__(self, chans, num_pools):\n",
    "        super().__init__()\n",
    "        self.unet = UnetModel(\n",
    "            in_chans=2,\n",
    "            out_chans=2,\n",
    "            chans=chans,\n",
    "            num_pool_layers=num_pools,\n",
    "            drop_prob=0\n",
    "        )\n",
    "\n",
    "    def complex_to_chan_dim(self, x):\n",
    "        b, c, h, w, two = x.shape\n",
    "        assert two == 2\n",
    "        return x.permute(0, 4, 1, 2, 3).contiguous().view(b, 2 * c, h, w)\n",
    "\n",
    "    def chan_complex_to_last_dim(self, x):\n",
    "        b, c2, h, w = x.shape\n",
    "        assert c2 % 2 == 0\n",
    "        c = c2 // 2\n",
    "        return x.view(b, 2, c, h, w).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "    def norm(self, x):\n",
    "        # Group norm\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.contiguous().view(b, 2, c // 2 * h * w)\n",
    "        mean = x.mean(dim=2).view(b, 2, 1, 1, 1).expand(\n",
    "            b, 2, c // 2, 1, 1).contiguous().view(b, c, 1, 1)\n",
    "        std = x.std(dim=2).view(b, 2, 1, 1, 1).expand(\n",
    "            b, 2, c // 2, 1, 1).contiguous().view(b, c, 1, 1)\n",
    "        x = x.view(b, c, h, w)\n",
    "        return (x - mean) / std, mean, std\n",
    "\n",
    "    def unnorm(self, x, mean, std):\n",
    "        return x * std + mean\n",
    "\n",
    "    def pad(self, x):\n",
    "        def floor_ceil(n):\n",
    "            return math.floor(n), math.ceil(n)\n",
    "\n",
    "        b, c, h, w = x.shape\n",
    "        w_mult = ((w - 1) | 15) + 1\n",
    "        h_mult = ((h - 1) | 15) + 1\n",
    "        w_pad = floor_ceil((w_mult - w) / 2)\n",
    "        h_pad = floor_ceil((h_mult - h) / 2)\n",
    "        x = F.pad(x, w_pad + h_pad)\n",
    "        return x, (h_pad, w_pad, h_mult, w_mult)\n",
    "\n",
    "    def unpad(self, x, h_pad, w_pad, h_mult, w_mult):\n",
    "        return x[..., h_pad[0]:h_mult - h_pad[1], w_pad[0]:w_mult - w_pad[1]]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.complex_to_chan_dim(x)\n",
    "        x, mean, std = self.norm(x)\n",
    "        x, pad_sizes = self.pad(x)\n",
    "        x = self.unet(x)\n",
    "        x = self.unpad(x, *pad_sizes)\n",
    "        x = self.unnorm(x, mean, std)\n",
    "        x = self.chan_complex_to_last_dim(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormUnet(\n",
       "  (unet): UnetModel(\n",
       "    (down_sample_layers): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(2, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(18, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(18, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(72, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(72, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(72, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(144, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(144, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv): ConvBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        (3): Dropout2d(p=0)\n",
       "        (4): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (5): InstanceNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        (7): Dropout2d(p=0)\n",
       "      )\n",
       "    )\n",
       "    (up_conv): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(288, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(144, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(144, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(144, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(72, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(72, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(72, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (3): Dropout2d(p=0)\n",
       "          (4): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "          (7): Dropout2d(p=0)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(36, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): InstanceNorm2d(18, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "            (3): Dropout2d(p=0)\n",
       "            (4): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (5): InstanceNorm2d(18, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (6): LeakyReLU(negative_slope=0.2, inplace)\n",
       "            (7): Dropout2d(p=0)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up_transpose_conv): ModuleList(\n",
       "      (0): TransposeConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): ConvTranspose2d(288, 144, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "          (1): InstanceNorm2d(144, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        )\n",
       "      )\n",
       "      (1): TransposeConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): ConvTranspose2d(144, 72, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "          (1): InstanceNorm2d(72, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        )\n",
       "      )\n",
       "      (2): TransposeConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): ConvTranspose2d(72, 36, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "          (1): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        )\n",
       "      )\n",
       "      (3): TransposeConvBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): ConvTranspose2d(36, 18, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "          (1): InstanceNorm2d(18, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NormUnet(18,4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'data.transforms' has no attribute 'count_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e984d2daa4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameters in Model=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'data.transforms' has no attribute 'count_parameters'"
     ]
    }
   ],
   "source": [
    "print(\"Parameters in Model=\",T.count_parameters(model)/1000000,\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensitivityModel(nn.Module):\n",
    "    def __init__(self, chans, num_pools):\n",
    "        super().__init__()\n",
    "        self.norm_unet = NormUnet(chans, num_pools)\n",
    "\n",
    "    def chans_to_batch_dim(self, x):\n",
    "        b, c, *other = x.shape\n",
    "        return x.contiguous().view(b * c, 1, *other), b\n",
    "\n",
    "    def batch_chans_to_chan_dim(self, x, batch_size):\n",
    "        bc, one, *other = x.shape\n",
    "        c = bc // batch_size\n",
    "        return x.view(batch_size, c, *other)\n",
    "    \n",
    "    \n",
    "\n",
    "    def divide_root_sum_of_squares(self, x):\n",
    "        \n",
    "        def root_sum_of_squares_complex(data, dim=0):\n",
    "            \"\"\"\n",
    "            Compute the Root Sum of Squares (RSS) transform along a given dimension of a tensor.\n",
    "            Args:\n",
    "                data (torch.Tensor): The input tensor\n",
    "                dim (int): The dimensions along which to apply the RSS transform\n",
    "            Returns:\n",
    "                torch.Tensor: The RSS value\n",
    "            \"\"\"\n",
    "            return torch.sqrt(complex_abs_sq(data).sum(dim))\n",
    "        \n",
    "        def complex_abs_sq(data):\n",
    "            \"\"\"\n",
    "            Compute the squared absolute value of a complex tensor\n",
    "            \"\"\"\n",
    "            assert data.size(-1) == 2\n",
    "            return (data ** 2).sum(dim=-1)\n",
    "        return x / root_sum_of_squares_complex(x, dim=1).unsqueeze(-1).unsqueeze(1)\n",
    "\n",
    "    def forward(self, masked_kspace, mask):\n",
    "        \n",
    "#         def mask_centre(ksp,mask):\n",
    "#             mask = mask.squeeze(0)\n",
    "#             x_c = mask.shape[0]//2\n",
    "#             y_c = mask.shape[1]//2\n",
    "#             r = 0\n",
    "\n",
    "#             x_c2 = x_c\n",
    "#             y_c2 = y_c\n",
    "\n",
    "#             while (mask[x_c2,y_c2,0]):\n",
    "# #                 print(\"r=\",r)\n",
    "#                 r = r+1\n",
    "#                 x_c2 = x_c2+1\n",
    "#             r = r+2\n",
    "#             mask2 = torch.zeros_like(ksp)\n",
    "#             for x in range(x_c-r,x_c+r):\n",
    "#                 for y in range(y_c-r,y_c+r):\n",
    "#                     d = np.sqrt((x-x_c)**2+(y-y_c)**2)\n",
    "#                     if(d<=r):\n",
    "# #                         print(x,y)\n",
    "#                         mask2[:,:,x,y,:] = ksp[:,:,x,y,:] # b,32,218,180,2\n",
    "#             return mask2\n",
    "\n",
    "\n",
    "        def mask_centre(ksp,mask):\n",
    "            # print(\"mask\",mask.shape)\n",
    "            mask = mask.squeeze(0)\n",
    "            x_c = mask.shape[0]//2\n",
    "            y_c = mask.shape[1]//2\n",
    "            r = 0\n",
    "\n",
    "            x_c2 = x_c\n",
    "            y_c2 = y_c\n",
    "\n",
    "            while (mask[x_c2,y_c2,0]):\n",
    "        #                 print(\"r=\",r)\n",
    "                r = r+1\n",
    "                x_c2 = x_c2+1\n",
    "        #     r = r+2\n",
    "            mask2 = torch.zeros_like(ksp)\n",
    "        #     print(int(x_c-r//torch.sqrt(torch.tensor(2.0))))\n",
    "            \n",
    "            for x in range(int(x_c-r/torch.sqrt(torch.tensor(2.0))),int(x_c+r/torch.sqrt(torch.tensor(2.0)))):\n",
    "                for y in range(int(y_c-r/torch.sqrt(torch.tensor(2.0))),int(y_c+r/torch.sqrt(torch.tensor(2.0)))):\n",
    "        #             d = np.sqrt((x-x_c)**2+(y-y_c)**2)\n",
    "        #             if(d<=r):\n",
    "        #             print(x,y)\n",
    "                    mask2[:,:,x,y,:] = ksp[:,:,x,y,:] # b,32,218,180,2\n",
    "            return mask2\n",
    "\n",
    "        x = mask_centre(masked_kspace,mask)\n",
    "        x = T.ifft2(x)\n",
    "        x, b = self.chans_to_batch_dim(x)\n",
    "        x = self.norm_unet(x)\n",
    "        x = self.batch_chans_to_chan_dim(x, b)\n",
    "        \n",
    "        x = self.divide_root_sum_of_squares(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
