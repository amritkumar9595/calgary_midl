training VarNet with 12-channels data, using SSIM lossINFO:root:Namespace(acceleration=5, batch_size=1, center_fractions=[0.08], checkpoint='/home/ubuntu/volume1/MIDL-challenge/Amrit/experiments/varnet/acc_5x/12-channels/SSIM_loss/vs_model.pt', data_parallel=False, data_path=PosixPath('/home/ubuntu/volume1/MIDL-challenge/Data2'), device='cuda:0', drop_prob=0.0, dropout=0.0, exp_dir=PosixPath('/home/ubuntu/volume1/MIDL-challenge/Amrit/experiments/varnet/acc_5x/12-channels/SSIM_loss'), loss='SSIM', lr=0.001, lr_gamma=0.1, lr_step_size=40, num_chans=32, num_epochs=150, num_pools=4, report_interval=5000, residual='False', resume='False', sample_rate=0.1, seed=42, weight_decay=0.0)

INFO:root:network(
  (conv_blocks): ModuleList(
    (0): cnn_layer(
      (conv): Sequential(
        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
        (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): cnn_layer(
      (conv): Sequential(
        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
        (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (2): cnn_layer(
      (conv): Sequential(
        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
        (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (3): cnn_layer(
      (conv): Sequential(
        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
        (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (4): cnn_layer(
      (conv): Sequential(
        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU(inplace=True)
        (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (dc_blocks): ModuleList(
    (0): dataConsistencyTerm()
    (1): dataConsistencyTerm()
    (2): dataConsistencyTerm()
    (3): dataConsistencyTerm()
    (4): dataConsistencyTerm()
  )
  (wa_blocks): ModuleList(
    (0): weightedAverageTerm()
    (1): weightedAverageTerm()
    (2): weightedAverageTerm()
    (3): weightedAverageTerm()
    (4): weightedAverageTerm()
  )
)
INFO:root:SensitivityModel(
  (norm_unet): NormUnet(
    (unet): UnetModel(
      (down_sample_layers): ModuleList(
        (0): ConvBlock(in_chans=2, out_chans=32, drop_prob=0)
        (1): ConvBlock(in_chans=32, out_chans=64, drop_prob=0)
        (2): ConvBlock(in_chans=64, out_chans=128, drop_prob=0)
        (3): ConvBlock(in_chans=128, out_chans=256, drop_prob=0)
      )
      (conv): ConvBlock(in_chans=256, out_chans=512, drop_prob=0)
      (up_conv): ModuleList(
        (0): ConvBlock(in_chans=512, out_chans=256, drop_prob=0)
        (1): ConvBlock(in_chans=256, out_chans=128, drop_prob=0)
        (2): ConvBlock(in_chans=128, out_chans=64, drop_prob=0)
        (3): Sequential(
          (0): ConvBlock(in_chans=64, out_chans=32, drop_prob=0)
          (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (up_transpose_conv): ModuleList(
        (0): ConvBlock(in_chans=512, out_chans=256)
        (1): ConvBlock(in_chans=256, out_chans=128)
        (2): ConvBlock(in_chans=128, out_chans=64)
        (3): ConvBlock(in_chans=64, out_chans=32)
      )
    )
  )
)
dataloaders for 12 channels data readdy
Parameters in VS-Model= 565.78 K
Parameters in VS-Sens= 7756.418 K
Total parameters in VS-Model + VS-Sens = 8322.198 K
  0%|          | 0/733 [00:00<?, ?it/s]INFO:root:Epoch = [  0/150] Iter = [   0/ 733] Loss_cmplx = 0.7579 Avg Loss cmplx = 0.7579 Time = 1.9395s
  0%|          | 1/733 [00:01<23:39,  1.94s/it]  0%|          | 2/733 [00:02<17:01,  1.40s/it]  0%|          | 3/733 [00:02<12:23,  1.02s/it]  1%|          | 4/733 [00:02<09:08,  1.33it/s]  1%|          | 5/733 [00:02<06:50,  1.77it/s]  1%|          | 6/733 [00:02<05:20,  2.27it/s]  1%|          | 7/733 [00:02<04:12,  2.88it/s]  1%|          | 8/733 [00:02<03:26,  3.51it/s]  1%|          | 9/733 [00:03<02:52,  4.20it/s]  1%|▏         | 10/733 [00:03<02:28,  4.88it/s]  2%|▏         | 11/733 [00:03<02:14,  5.37it/s]  2%|▏         | 12/733 [00:03<02:01,  5.93it/s]  2%|▏         | 13/733 [00:03<01:53,  6.34it/s]  2%|▏         | 14/733 [00:03<01:49,  6.57it/s]  2%|▏         | 15/733 [00:03<01:47,  6.71it/s]  2%|▏         | 16/733 [00:03<01:42,  7.02it/s]  2%|▏         | 17/733 [00:04<01:39,  7.20it/s]  2%|▏         | 18/733 [00:04<01:37,  7.36it/s]  3%|▎         | 19/733 [00:04<01:35,  7.51it/s]  3%|▎         | 20/733 [00:04<01:37,  7.33it/s]  3%|▎         | 21/733 [00:04<01:38,  7.23it/s]  3%|▎         | 22/733 [00:04<01:35,  7.41it/s]  3%|▎         | 23/733 [00:04<01:34,  7.51it/s]  3%|▎         | 24/733 [00:05<01:33,  7.57it/s]  3%|▎         | 25/733 [00:05<01:34,  7.47it/s]  4%|▎         | 26/733 [00:05<01:33,  7.52it/s]  4%|▎         | 27/733 [00:05<01:32,  7.60it/s]  4%|▍         | 28/733 [00:05<01:33,  7.57it/s]  4%|▍         | 28/733 [00:05<02:24,  4.89it/s]
Traceback (most recent call last):
  File "train_var12.py", line 502, in <module>
    main(args)
  File "train_var12.py", line 436, in main
    train_loss_cmplx, train_time = train_epoch(args, epoch,  model_vs , model_sens ,  train_loader, optimizer_vs)
  File "train_var12.py", line 119, in train_epoch
    out,_ = model_vs(img_us,ksp_us,sens,mask)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/volume1/MIDL-challenge/Amrit/calgary_midl/models/models.py", line 570, in forward
    x_cnn = self.conv_blocks[i](x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/volume1/MIDL-challenge/Amrit/calgary_midl/models/models.py", line 538, in forward
    x = self.conv(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt
