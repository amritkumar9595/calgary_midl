{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bart import bart\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from data import transforms as T\n",
    "# from train_vs_sens import create_data_loaders, build_model\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from torch import nn\n",
    "import math\n",
    "from models.models import SSIM \n",
    "ssim_loss = SSIM().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_var12_pretext_sens import create_data_loaders , build_model , load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'center_fractions':[0.08],'accelerations':[4],'challenge':'singlecoil',\n",
    "       'data_path':Path('/media/student1/RemovableVolume/calgary'),\n",
    "        \n",
    "       'resolution':170,\n",
    "       'sample_rate':1,\n",
    "       'batch_size':1,\n",
    "        'device':'cuda',\n",
    "        'data_parallel':False,\n",
    "        'num_chans':32,\n",
    "        'num_pools':4,\n",
    "        'drop_prob':0,\n",
    "        'acceleration':5,\n",
    "        'dropout':0,\n",
    "       }\n",
    "# d_named = namedtuple(\"Employee\", d.keys())(*d.values())\n",
    "args = namedtuple('args',args.keys())(*args.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, dev_loader,display_loader = create_data_loaders(args,args.data_path)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter,data in enumerate(train_loader):\n",
    "    ksp_us,img_us,img_us_rss,img_us_np,img_gt_np,sens,mask,maxi,fname = data\n",
    "    break\n",
    "ksp_us = ksp_us.to(args.device)\n",
    "sens = sens.to(args.device)\n",
    "mask = mask.to(args.device)\n",
    "img_us = img_us.to(args.device)\n",
    "img_us_rss = img_us_rss.unsqueeze(0).to(args.device).float()\n",
    "img_gt_np = img_gt_np.unsqueeze(0).to(args.device).float()\n",
    "img_us_np = img_us_np.unsqueeze(0).to(args.device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_us_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ksp_us.shape,img_us.shape,img_us_rss.shape,img_us_np.shape,img_gt_np.shape,sens.shape,mask.shape,maxi,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_us.shape , img_gt_np.shape , sens.shape , fname)\n",
    "print(\"Channel-wise US image\") \n",
    "plt.figure(figsize = (8,6),dpi = 150)\n",
    "gs1 = gridspec.GridSpec(3, 4)\n",
    "gs1.update(wspace=0.002, hspace=0.1)\n",
    "\n",
    "for ii in range(12):\n",
    "    plt.subplot(gs1[ii])\n",
    "    plt.imshow(torch.sqrt(img_us[0,ii,:,:,0].detach().cpu()**2 + img_us[0,ii,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "#     plt.imshow(np.abs(sample_rec_train[:,:,ii]),cmap = \"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Channel-wise sensitivity maps\") \n",
    "plt.figure(figsize = (8,6),dpi = 150)\n",
    "gs1 = gridspec.GridSpec(3, 4)\n",
    "gs1.update(wspace=0.002, hspace=0.1)\n",
    "\n",
    "for ii in range(12):\n",
    "    plt.subplot(gs1[ii])\n",
    "    plt.imshow(torch.sqrt(sens[0,ii,:,:,0].detach().cpu()**2 + sens[0,ii,:,:,1].detach().cpu()**2),cmap='gray')\n",
    "#     plt.imshow(np.abs(sample_rec_train[:,:,ii]),cmap = \"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecure_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "architecture_unet(\n",
       "  (model_vs): network_unet(\n",
       "    (conv_blocks): ModuleList(\n",
       "      (0): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): NormUnet(\n",
       "        (unet): UnetModel(\n",
       "          (down_sample_layers): ModuleList(\n",
       "            (0): ConvBlock(in_chans=2, out_chans=18, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=18, out_chans=36, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=36, out_chans=72, drop_prob=0)\n",
       "            (3): ConvBlock(in_chans=72, out_chans=144, drop_prob=0)\n",
       "          )\n",
       "          (conv): ConvBlock(in_chans=144, out_chans=288, drop_prob=0)\n",
       "          (up_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144, drop_prob=0)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72, drop_prob=0)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36, drop_prob=0)\n",
       "            (3): Sequential(\n",
       "              (0): ConvBlock(in_chans=36, out_chans=18, drop_prob=0)\n",
       "              (1): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up_transpose_conv): ModuleList(\n",
       "            (0): ConvBlock(in_chans=288, out_chans=144)\n",
       "            (1): ConvBlock(in_chans=144, out_chans=72)\n",
       "            (2): ConvBlock(in_chans=72, out_chans=36)\n",
       "            (3): ConvBlock(in_chans=36, out_chans=18)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dc_blocks): ModuleList(\n",
       "      (0): dataConsistencyTerm()\n",
       "      (1): dataConsistencyTerm()\n",
       "      (2): dataConsistencyTerm()\n",
       "      (3): dataConsistencyTerm()\n",
       "      (4): dataConsistencyTerm()\n",
       "      (5): dataConsistencyTerm()\n",
       "      (6): dataConsistencyTerm()\n",
       "      (7): dataConsistencyTerm()\n",
       "      (8): dataConsistencyTerm()\n",
       "      (9): dataConsistencyTerm()\n",
       "      (10): dataConsistencyTerm()\n",
       "      (11): dataConsistencyTerm()\n",
       "    )\n",
       "    (wa_blocks): ModuleList(\n",
       "      (0): weightedAverageTerm()\n",
       "      (1): weightedAverageTerm()\n",
       "      (2): weightedAverageTerm()\n",
       "      (3): weightedAverageTerm()\n",
       "      (4): weightedAverageTerm()\n",
       "      (5): weightedAverageTerm()\n",
       "      (6): weightedAverageTerm()\n",
       "      (7): weightedAverageTerm()\n",
       "      (8): weightedAverageTerm()\n",
       "      (9): weightedAverageTerm()\n",
       "      (10): weightedAverageTerm()\n",
       "      (11): weightedAverageTerm()\n",
       "    )\n",
       "  )\n",
       "  (model_sens): SensitivityModel(\n",
       "    (norm_unet): NormUnet(\n",
       "      (unet): UnetModel(\n",
       "        (down_sample_layers): ModuleList(\n",
       "          (0): ConvBlock(in_chans=2, out_chans=8, drop_prob=0)\n",
       "          (1): ConvBlock(in_chans=8, out_chans=16, drop_prob=0)\n",
       "          (2): ConvBlock(in_chans=16, out_chans=32, drop_prob=0)\n",
       "          (3): ConvBlock(in_chans=32, out_chans=64, drop_prob=0)\n",
       "        )\n",
       "        (conv): ConvBlock(in_chans=64, out_chans=128, drop_prob=0)\n",
       "        (up_conv): ModuleList(\n",
       "          (0): ConvBlock(in_chans=128, out_chans=64, drop_prob=0)\n",
       "          (1): ConvBlock(in_chans=64, out_chans=32, drop_prob=0)\n",
       "          (2): ConvBlock(in_chans=32, out_chans=16, drop_prob=0)\n",
       "          (3): Sequential(\n",
       "            (0): ConvBlock(in_chans=16, out_chans=8, drop_prob=0)\n",
       "            (1): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (up_transpose_conv): ModuleList(\n",
       "          (0): ConvBlock(in_chans=128, out_chans=64)\n",
       "          (1): ConvBlock(in_chans=64, out_chans=32)\n",
       "          (2): ConvBlock(in_chans=32, out_chans=16)\n",
       "          (3): ConvBlock(in_chans=16, out_chans=8)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.models import architecture_unet,architecture_sens\n",
    "wacoeff = 0.1\n",
    "dccoeff = 0.1\n",
    "cascade = 12  \n",
    "sens_chans = 8\n",
    "sens_pools = 4\n",
    "\n",
    "model = architecture_unet(dccoeff, wacoeff, cascade,sens_chans, sens_pools).to(args.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters() , 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5\n",
    "losses = []\n",
    "# pha_loss = []\n",
    "\n",
    "# model_pha.train()\n",
    "for _ in tqdm(range(epochs)):\n",
    "    \n",
    "    out , _,_ = model(img_us.cuda(),ksp_us.cuda(), mask.cuda())\n",
    "#     out = out.squeeze(0)\n",
    "    loss = ssim_loss(out, img_us_np,torch.tensor(img_gt_np.max().item()).unsqueeze(0).cuda())\n",
    "        \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb1d8865b00>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8VGXe/vHPN51eTJQSIJGmSCciNWBBIiJYcAVWBXVBUZquu7ruPrs+uP7cKh0R115AxFURUQREE6oEadJC6JEWuoD0+/dHxmezMZgJJHMymev9euW1M2fuYa4cd665M3POPeacQ0REQkOY1wFERCRwVPoiIiFEpS8iEkJU+iIiIUSlLyISQlT6IiIhRKUvIhJCVPoiIiFEpS8iEkIivA6QV2xsrEtISPA6hohIUFm2bNk+51xcQeNKXOknJCSQnp7udQwRkaBiZtv8Gae3d0REQohKX0QkhKj0RURCiEpfRCSEqPRFREKISl9EJISo9EVEQohfpW9mKWa2wcwyzezJfG6vY2ZzzWyVmX1pZvG5butnZht9P/2KMnxuzjme/WQta3YeLq6HEBEJegWWvpmFA+OBm4BGQB8za5Rn2D+AN5xzTYERwHO++1YF/gRcA7QG/mRmVYou/n9s3X+cKUt3cPOY+Tz05jLW7z5SHA8jIhLU/JnptwYynXObnXOngClAzzxjGgFzfZfn5bq9KzDbOXfAOXcQmA2kXHzsn0qMLcf8J65j6PX1WZC5j5RRaTzy9jdk7Pm+OB5ORCQo+VP6NYEdua5n+bblthK4w3f5NqCCmV3i530xs4Fmlm5m6dnZ2f5m/4lKZSJ5rEsD0p64lsHX1uPLDXvpOiqVIZOXk7lX5S8i4k/pWz7bXJ7rjwOdzGw50An4Djjj531xzk1yziU555Li4gpcL6hAlctG8XjXhsx/4joGdarL3HV76DIylWFTlrMp++hF//siIsHKn9LPAmrluh4P7Mw9wDm30zl3u3OuBfB737bD/ty3OFUpF8VvU64g7bfXMjD5cj5fs4cuz3/FY++uYMu+Y4GKISJSYphzP5l4//cAswggA7ienBn8UqCvc25NrjGxwAHn3DkzexY465z7o++D3GVAS9/Qb4BWzrkD53u8pKQkV1yrbO47epJJqZt5Y9FWTp913Nq8JkOvr0edS8oVy+OJiASKmS1zziUVNK7Amb5z7gwwGJgFrAOmOufWmNkIM+vhG9YZ2GBmGcBlwLO++x4AniHnhWIpMOLnCr+4xZaP5qluV5L622vp3y6BGat2ct0/v+K301ay48Bxr2KJiARMgTP9QCvOmX5ee4+c4IWvNvH2ku2cO+fo1SqeR66tR62qZQPy+CIiRcXfmX5Il/6Pdh8+wQtfZjL56x04HHcm1eKRa+tRs3KZgOYQEblQKv0LsOvwD0yYt4kpS7cDcNfVOeVfvZLKX0RKNpX+Rfju0A+Mn5fJ1KU7CDOjT+taPHxtPS6rGONpLhGR81HpF4EdB44zfl4m05ZlERZm9G1dm4c71+VSlb+IlDAq/SK0ff9xxs3byPvffEdEmHF3mzo81KkucRWivY4mIgKo9IvF1n3HGPtFJh8szyIqIox72yYwMPlyYsur/EXEWyr9YrRl3zHGzt3Ihyu+IzoinHvb1eHB5LpULRfldTQRCVEq/QDYlH2UMXM3Mn3lTspGhtOvXQIDOl5OFZW/iASYSj+ANu75ntFzN/LJ6l2Ui4qgf7sEftUxkcplVf4iEhgqfQ9k7Pme0XNyyr9CdAT3dUjkgQ6JVCoT6XU0ESnlVPoeWrfrCKPnbOSzNbupEBPBAx0Sub9DIhVjVP4iUjxU+iXAmp2HGT1nI5+v3UPFmAgGdLyc/u0TqKDyF5EiptIvQb797jCj5mQwZ91eKpeNZEDHy+nXLoHy0RFeRxORUkKlXwKtyjrEqDkb+WL9XqqUjWRgcl3ubVuHcip/EblIKv0SbMWOQ4ycncFXGdlULRfFQ50u5+42dSgbpfIXkQuj0g8Cy7YdZNScDNI27iO2fBQPdarLL6+pQ5mocK+jiUiQUekHkfStBxg5J4MFmfuJqxDNoE516XtNbWIiVf4i4h+VfhBasnk/I+dksHjzAS6tEM3DnevSu7XKX0QKptIPYos25ZT/11sOUK1iDI9cW5dfXF2L6AiVv4jkT6Uf5JxzLNy0n5GzM0jfdpAalWJ45Lp63NmqFlERBX6fvYiEGJV+KeGcY37mPkbOzuCb7YeoWbkMg6+rR69W8USGq/xFJIdKv5RxzvFVRjYj52xk5Y5DxFcpw9Dr6nNby5oqfxFR6ZdWzjm+3JDNyDkZrMo6TO2qZRlyXT1ua1GTCJW/SMhS6ZdyzjnmrtvLyDkZrNl5hIRLyjL0+vr0aFZD5S8Sgvwtfb/awcxSzGyDmWWa2ZP53F7bzOaZ2XIzW2Vm3XzbE8zsBzNb4fuZWPhfRfJjZtzQ6DJmDOnApHtaUSYqgsemruTGkal8uPw7zp4rWS/mIlIyFDjTN7NwIAPoAmQBS4E+zrm1ucZMApY7514ws0bATOdcgpklADOcc439DaSZ/oU5d87x+drdjJqzkfW7v6duXDmG3dCAm5tUJzzMvI4nIsWsKGf6rYFM59xm59wpYArQM88YB1T0Xa4E7CxMWLl4YWFGSuPqzBzakQm/bEl4mDF08nJSRqUyY9VOzmnmLyL4V/o1gR25rmf5tuX2NHC3mWUBM4EhuW5L9L3t85WZdbyYsFKwsDCjW5PqfDYsmbF9WuCAwe8s56bRaXy6epfKXyTE+VP6+b03kLc5+gCvOefigW7Am2YWBuwCajvnWgCPAe+YWcU898XMBppZupmlZ2dnF+43kHyFhRm3NKvBrOHJjO7dnNPnzjHo7W/oNiaNz77dTUn7AF9EAsOf0s8CauW6Hs9P3755AJgK4JxbBMQAsc65k865/b7ty4BNQIO8D+Ccm+ScS3LOJcXFxRX+t5DzCg8zejavyexHOzHyrmacOH2Wh95aRvex85m9do/KXyTE+FP6S4H6ZpZoZlFAb2B6njHbgesBzOxKcko/28zifB8EY2aXA/WBzUUVXvwXHmbc1iKeOY914h93NuPoyTMMeCOde1/5mt2HT3gdT0QCpMDSd86dAQYDs4B1wFTn3BozG2FmPXzDfg0MMLOVwGSgv8uZQiYDq3zbpwEPOecOFMcvIv6JCA+jV6uc8h/R8yrStx6k66hUpq/UZ+8ioUAnZ4W4LfuO8djUFSzffohbmtXgzz0bU6msvrhdJNgU6clZUnolxpbjvQfb8usuDfh09S66jkolbaM+TBcprVT6QkR4GEOur88HD7enXHQ497z8NU9PX8MPp856HU1EiphKX/5Pk/hKfDK0I/3bJfDawq10H5vGqqxDXscSkSKk0pf/EhMZztM9ruKtB67h2Mmz3D5hIWPmbuTM2XNeRxORIqDSl3x1qB/LrOHJdGtSnednZ9Br4iK27DvmdSwRuUgqfTmvSmUjGdOnBWP7tGDLvmN0G53GW4u36YQukSCm0pcC/bicQ1JCFf7w4bfc99pS9h7RCV0iwUilL36pVimGN+5vzYieV7F48366jkpl5updXscSkUJS6YvfzIx72ybwydCO1K5aloff/obH3l3BkROnvY4mIn5S6Uuh1Y0rz7RB7Rh2fX0+WrmTlJGpLNy0z+tYIuIHlb5ckMjwMB7t0oD3B7UjOjKcvi8t4ZkZazlxWid0iZRkKn25KM1rVeaToR24p00dXp6/hR7j5vPtd4e9jiUi56HSl4tWNiqCZ25tzGv3Xc2h46e5bcICxs/L1Jezi5RAKn0pMp0bXsqs4cnc2Kgaf5+1gbteXMT2/ce9jiUiuaj0pUhVKRfFuL4tGHVXczbs+Z6U0alM+Xq7TugSKSFU+lLkzIxbW9Rk1vBkmteqzJP/Xs2AN9LJ/v6k19FEQp5KX4pNjcpleOuBa/hj90akbtxH11GpzFqz2+tYIiFNpS/FKizMuL9DIp8M6UD1SjE8+OYyfvPeSr7XCV0inlDpS0DUv6wCHzzcnsHX1uP9b7K4aXQaSzbv9zqWSMhR6UvAREWE8XjXhrz3UFvCw4zeLy3muU/XcfKMTugSCRSVvgRcqzpVmTm0I72vrs2LX22m57gFrNt1xOtYIiFBpS+eKBcdwXO3N+HlfknsO3qKnuMW8OJXm3RCl0gxU+mLp66/8jJmDe/ItVfE8dyn6+nz0mJ2HNAJXSLFRaUvnrukfDQT727FP+5sxtqdR7hpdBrvpe/QCV0ixUClLyWCmdGrVTyfDutIoxoV+c20VTz01jL2H9UJXSJFya/SN7MUM9tgZplm9mQ+t9c2s3lmttzMVplZt1y3/c53vw1m1rUow0vpU6tqWSYPaMNT3a5g3vpsuo5KZe66PV7HEik1Cix9MwsHxgM3AY2APmbWKM+wPwBTnXMtgN7ABN99G/muXwWkABN8/57IeYWHGQOT6zJ9SHtiy0fzwOvp/O7fqzh28ozX0USCnj8z/dZApnNus3PuFDAF6JlnjAMq+i5XAnb6LvcEpjjnTjrntgCZvn9PpEBXVKvIR4Pb81CnukxZuoObRqexbNsBr2OJBDV/Sr8msCPX9SzfttyeBu42syxgJjCkEPfFzAaaWbqZpWdnZ/sZXUJBdEQ4T950Be8ObMs557hz4iL+Pms9p86c8zqaSFDyp/Qtn215D6voA7zmnIsHugFvmlmYn/fFOTfJOZfknEuKi4vzI5KEmtaJVfl0WEd6tYpn/LxN3DZhARl7vvc6lkjQ8af0s4Baua7H85+3b370ADAVwDm3CIgBYv28r4hfKsRE8rdezZh0Tyt2Hz5B97HzeXn+Fs7phC4Rv/lT+kuB+maWaGZR5HwwOz3PmO3A9QBmdiU5pZ/tG9fbzKLNLBGoD3xdVOElNN14VTU+G55Mcv1YnpmxlrtfXsJ3h37wOpZIUCiw9J1zZ4DBwCxgHTlH6awxsxFm1sM37NfAADNbCUwG+rsca8j5C2At8BnwiHNOq2vJRYurEM1L9ybxl9ubsGLHIVJGpfLB8iyd0CVSACtpT5KkpCSXnp7udQwJItv2H+PXU1eSvu0g3ZpU49lbm1ClXJTXsUQCysyWOeeSChqnM3Il6NW5pBzvPtiW36Y0ZPbaPXQdlcqXG/Z6HUukRFLpS6kQHmY83LkeHz7SnsplI+n/6lL+8OFqjp/SCV0iuan0pVS5qkYlpg/uwK86JPL2ku3cPGY+y7cf9DqWSImh0pdSJyYynD90b8Tbv7qGk6fP0mviIp6fncHpszqhS0SlL6VWu7qxfPZoMj2b12DM3I3c8cJCMvce9TqWiKdU+lKqVYyJ5PlfNGfCL1uy/cBxbh6TxusLt+qELglZKn0JCd2aVOfz4cm0rXsJf5q+hn6vfs3uwye8jiUScCp9CRmXVozh1f5X8+dbG5O+9SBdR6UyfaVWBZHQotKXkGJm3N2mDjOHdSQxthxDJy9nyOTlHD5+2utoIgGh0peQlBhbjmkPteXXXRrw6epddB2VStpGLestpZ9KX0JWRHgYQ66vzwcPt6dcdDj3vPw1T09fww+ntDyUlF4qfQl5TeIr8cnQjvRvl8BrC7fSfWwaq7IOeR1LpFio9EXIOaHr6R5X8dYD13Ds5Flun7CQMXM3ckYndEkpo9IXyaVD/VhmDU+mW5PqPD87g14TF7Fl3zGvY4kUGZW+SB6VykYypk8LxvRpwebso3QbncZbi7dprX4pFVT6IufRo1kNPn+0E0kJVfjDh99y32tL2XtEJ3RJcFPpi/yMapVieP2+1vxvj6tYtGk/N41O01r9EtRU+iIFCAsz+rVLYMaQDsSWj6b/q0t5buY6rdopQUmlL+Kn+pdV4KPB7fnlNbV5MXUzd05cxI4Dx72OJVIoKn2RQoiJDOfZ25owvm9LNvk+5P1k1S6vY4n4TaUvcgFublqdmUM7UvfS8jzyzjc89cFqTpzWmbxS8qn0RS5Qraplee+htjzY6XLeWbKdnuMWsHHP917HEvlZKn2RixAZHsbvbrqS1+67mn1HT3LLuPm8u3S7jumXEkulL1IEOje8lE+HdaRl7So88f5qhk1ZwfcntFyzlDx+lb6ZpZjZBjPLNLMn87l9pJmt8P1kmNmhXLedzXXb9KIML1KSXFoxhjcfuIbHb2zAJ6t30X3sfC3cJiWOFfRnqJmFAxlAFyALWAr0cc6tPc/4IUAL59z9vutHnXPl/Q2UlJTk0tPT/R0uUiIt3XqAYZOXk330JE+kXMEDHRIxM69jSSlmZsucc0kFjfNnpt8ayHTObXbOnQKmAD1/ZnwfYLJ/MUVKp6sTqjJzWEc6N7yUP3+yjgdeT+fAsVNexxLxq/RrAjtyXc/ybfsJM6sDJAJf5NocY2bpZrbYzG694KQiQaZy2Sgm3dOKp29pxPyN+7hpdCqLN+/3OpaEOH9KP7+/Sc/3nlBvYJpzLvcBy7V9f3L0BUaZWd2fPIDZQN8LQ3p2tr6yTkoPM6N/+0T+/XA7ykZF0PelxYyak8HZczq6R7zhT+lnAbVyXY8Hdp5nbG/yvLXjnNvp+9/NwJdAi7x3cs5Ncs4lOeeS4uLi/IgkElwa16zEx0M6cGvzmoyas5G+Ly1m92Gt2CmB50/pLwXqm1mimUWRU+w/OQrHzBoCVYBFubZVMbNo3+VYoD2Q7wfAIqVd+egInr+rOf+8sxmrvzvMTaNT+WL9Hq9jSYgpsPSdc2eAwcAsYB0w1Tm3xsxGmFmPXEP7AFPcfx8OdCWQbmYrgXnAX8531I9IqLijVTwfD+lAtUpluP+1dJ6ZsZZTZ7RipwRGgYdsBpoO2ZRQceL0Wf7fzHW8sWgbTeMrMbZPC+pcUs7rWBKkivKQTREpBjGR4Yzo2ZiJd7di675j3DxmPtNXnu/jMpGiodIX8VhK42rMHNaRhtUqMHTycp6Ytorjp854HUtKKZW+SAkQX6UsUwa24eHOdZm6bAc9xi1gw26t2ClFT6UvUkJEhofx25QreOP+1hw6fpoe4+bzzhKt2ClFS6UvUsJ0rB/Hp8M60jqxKk99sJrB7yzn8A9asVOKhkpfpASKqxDN6/e15omUK/hszW5uHpPG8u0HvY4lpYBKX6SECgszBnWuy9QH2+Ic3DlxES9+tYlzWsJBLoJKX6SEa1WnCjOHduSGKy/juU/Xc99rS9l39KTXsSRIqfRFgkClspG8cHdLnrm1MYs276fb6DQWZu7zOpYEIZW+SJAwM+5pU4ePHmlPhZgIfvnyEv75+QbOnNUSDuI/lb5IkLmyekU+HtKBO1rGM/aLTPq8tJidh37wOpYECZW+SBAqGxXBP+5sxsi7mrF25xFuGp3G7LVasVMKptIXCWK3tYhnxtCO1KpahgFvpPP09DWcPHO24DtKyFLpiwS5xNhyvD+oHfe1T+C1hVu5fcJCtuw75nUsKaFU+iKlQHREOH+65SpeujeJ7w79QPcxaXywPMvrWFICqfRFSpEujS5j5tCONKpRkUffXcmvp67k2Emt2Cn/odIXKWVqVC7D5AFtGHpdPf69PItbxs1n7c4jXseSEkKlL1IKRYSH8diNDXn7V9dw9MQZbp2wgDcXbdWKnaLSFynN2tWNZeawjrSrewn/89EaBr31DYePa8XOUKbSFynlYstH80q/q3mq2xXMWbeHbmPSWLbtgNexxCMqfZEQEBZmDEyuy7RB7QgLg1+8uJgJX2Zqxc4QpNIXCSHNa1Xmk6EdSbmqGn/7bAP9Xv2a7O+1YmcoUemLhJiKMZGM69uC525vwtdbDnDT6DTSNmZ7HUsCRKUvEoLMjD6tazN9cAeqlI3k3le+5q+free0Vuws9fwqfTNLMbMNZpZpZk/mc/tIM1vh+8kws0O5butnZht9P/2KMryIXJyG1SowfXAH7kqqxQtfbuKuFxeRdfC417GkGFlBx+2aWTiQAXQBsoClQB/n3NrzjB8CtHDO3W9mVYF0IAlwwDKglXPuvF/2mZSU5NLT0y/kdxGRizB95U6e+vdqwgz+1qspKY2rex1JCsHMljnnkgoa589MvzWQ6Zzb7Jw7BUwBev7M+D7AZN/lrsBs59wBX9HPBlL8eEwRCbAezWrwydAOJMSW46G3vuF/PvyWE6e1Ymdp40/p1wR25Lqe5dv2E2ZWB0gEvijsfUXEe3UuKce0h9oxoGMiby7exq3jF5C596jXsaQI+VP6ls+2870n1BuY5pz7cXrg133NbKCZpZtZena2jiIQ8VJURBi/v7kRr/RPYs+RE9wydj7TlmnFztLCn9LPAmrluh4P7DzP2N78560dv+/rnJvknEtyziXFxcX5EUlEitt1V1zGp8OSaRpficffW8lj767gqFbsDHr+lP5SoL6ZJZpZFDnFPj3vIDNrCFQBFuXaPAu40cyqmFkV4EbfNhEJAtUqxfDOgDY8ekMDPlzxHbeMnc+33x32OpZchAJL3zl3BhhMTlmvA6Y659aY2Qgz65FraB9gist1OJBz7gDwDDkvHEuBEb5tIhIkwsOMYTfU550Bbfjh1Flun7CQVxds0YqdQarAQzYDTYdsipRcB46d4jfvrWTu+r3ccOVl/L1XU6qUi/I6llC0h2yKiABQtVwU/+qXxP90b8RXGXvpNiaNpVv1x3swUemLSKGYGQ90SOT9Qe2IigjjrhcXMXbuRs5qxc6goNIXkQvSNL4yM4Z0oHvTGvxzdgb3vLyEvUdOeB1LCqDSF5ELViEmktG9m/O3O5ryzfaD3DQ6jS837PU6lvwMlb6IXBQz4xdX12LGkA7Elo+m/6tLeW7mOq3YWUKp9EWkSNS7tAIfDW7PL6+pzYupm7lz4iK279eKnSWNSl9EikxMZDjP3taE8X1bsin7KCmjU3lz8TZ9LWMJotIXkSJ3c9PqfDY8mVZ1qvA/H35L338t1qy/hFDpi0ixqFm5DG/c35q/3N6Eb787QtdRqby+cKtm/R5T6YtIsTEzereuzeePJtM6sSp/mr6G3i8tZtv+Y15HC1kqfREpdjUql+G1+67mb72asm5Xzqz/lflbNOv3gEpfRALCzPhFUi0+fzSZtpdfwogZa7lr0iK27NOsP5BU+iISUNUrleGV/lfzzzubsWH396SMSuVfaZu1jEOAqPRFJODMjDtaxTP7sU50qBfLnz9Zx50TF7IpW1/NWNxU+iLimcsqxvCvfkmMvKsZm7KP0W10GpNSN2nWX4xU+iLiKTPjthbxzH40meQGcfy/mevpNXEhmXu/9zpaqaTSF5ES4dKKMUy6pxWjezdn675jdBsznxe+3MQZreFTpFT6IlJimBk9m9fk80c7cV3DS/nrZ+u544WFZOzRrL+oqPRFpMSJqxDNC3e3ZFzfFuw4+APdx8xn/LxMzfqLgEpfREokM6N70xrMfjSZLlddxt9nbeC2CQtZv/uI19GCmkpfREq0S8pHM75vSyb8siU7D/3ALWPnM3buRq3Xf4FU+iISFLo1qc7sxzqR0rg6/5ydwa3jF7Bul2b9haXSF5GgUbVcFGP7tGDi3a3Yc+Qkt4ydz6g5GZw6o1m/v1T6IhJ0UhpXY/ajyXRvWp1RczbSc/wC1uw87HWsoKDSF5GgVKVcFKN6t2DSPa3Yd/QkPcct4PnZmvUXxK/SN7MUM9tgZplm9uR5xvzCzNaa2RozeyfX9rNmtsL3M72ogouIANx4Vc6sv0fzGoyZu5Ee4+bz7Xea9Z+POffza1yYWTiQAXQBsoClQB/n3NpcY+oDU4HrnHMHzexS59xe321HnXPl/Q2UlJTk0tPTC/+biEjIm7tuD099sJp9R08xqFNdhlxfj+iIcK9jBYSZLXPOJRU0zp+Zfmsg0zm32Tl3CpgC9MwzZgAw3jl3EODHwhcRCaTrr7yMz4d34rYWNRk3L5Nbxs5nVdYhr2OVKP6Ufk1gR67rWb5tuTUAGpjZAjNbbGYpuW6LMbN03/ZbLzKviMjPqlQ2kn/c2YxX77uaIz+c4bYJC/nrZ+s5cfqs19FKBH9K3/LZlvc9oQigPtAZ6AP8y8wq+26r7fuToy8wyszq/uQBzAb6XhjSs7Oz/Q4vInI+1za8lM8fS6ZXy3he+HIT3cfOZ/n2g17H8pw/pZ8F1Mp1PR7Ymc+Yj5xzp51zW4AN5LwI4Jzb6fvfzcCXQIu8D+Ccm+ScS3LOJcXFxRX6lxARyU/FmEj+2qspr9/fmmMnz3DHCwt57tN1IT3r96f0lwL1zSzRzKKA3kDeo3A+BK4FMLNYct7u2WxmVcwsOtf29sBaREQCqFODOD5/NJm7rq7Ni19t5uYxaSzbFpqz/gJL3zl3BhgMzALWAVOdc2vMbISZ9fANmwXsN7O1wDzgN865/cCVQLqZrfRt/0vuo35ERAKlQkwkz93ehDcfaM2J0+foNXEhz36yNuRm/QUeshloOmRTRIrb0ZNneG7mOt5esp3LY8vxt15NSUqo6nWsi1KUh2yKiJQq5aMjePa2Jrzzq2s4dfYcd764iBEfr+WHU6V/1q/SF5GQ1a5eLLOGJ3NPmzq8smALN41O5estB7yOVaxU+iIS0spFRzCiZ2MmD2jDWee4a9Iinp6+huOnzngdrVio9EVEgLZ1L2HW8GT6tU3gtYVbSRmVxuLN+72OVeRU+iIiPmWjIni6x1W8O7ANZtB70mL++NG3HDtZemb9Kn0RkTyuufwSPhuWzP3tE3lz8Ta6jkplYeY+r2MVCZW+iEg+ykSF88dbGvHeg22JDA+j77+W8PsPVnM0yGf9Kn0RkZ+RlFCVmUM7MqBjIu98vZ2uI1OZvzF4Z/0qfRGRApSJCuf3Nzdi2kNtiY4M4+6Xl/C7f6/i+xOnvY5WaCp9ERE/taqTM+t/MPly3l26g64jU/kqI7hWBlbpi4gUQkxkOL/rdiXvD2pH2egI+r3yNU9MW8WRIJn1q/RFRC5Ai9pVmDGkA4M61+W9ZTu48flU5q0v+V8aqNIXEblAMZHhPJFyBR883J6KZSK477WlPP7eSg4fL7mzfpW+iMhFalarMh8P6cDga+vxwfLvuHHUV8xdt8frWPlS6YuIFIHoiHAe79qQDx9uT+UyUTzwejqPvbuCQ8dPeR2ceUoTAAAG10lEQVTtv6j0RUSKUJP4Snw8pANDr6vH9JU76TIyldlrS86sX6UvIlLEoiLCeOzGhnz4SHtiy0cz4I10hk9ZzsFj3s/6VfoiIsWkcc1KfPRIe4bfUJ8Zq3bRZWQqn32729NMKn0RkWIUFRHG8BsaMH1wBy6tEM1Dby1jyOTlHPBo1q/SFxEJgEY1KvLR4Pb8uksDPvt2F12e/4qZq3cFPIdKX0QkQCLDwxhyfX0+HtKB6pVjePjtb3jk7W/Yd/RkwDKo9EVEAuyKahX54OH2/KZrQ2av3cONI1OZsWonzrlif2yVvoiIByLDw3jk2nrMGNqBWlXKMPid5QyevJxz54q3+COK9V8XEZGf1eCyCrw/qB0vpW3h2MkzhIVZsT6eXzN9M0sxsw1mlmlmT55nzC/MbK2ZrTGzd3Jt72dmG30//YoquIhIaRERHsagznV5vGvD4n+sggaYWTgwHugCZAFLzWy6c25trjH1gd8B7Z1zB83sUt/2qsCfgCTAAct89z1Y9L+KiIgUxJ+Zfmsg0zm32Tl3CpgC9MwzZgAw/scyd879uL5oV2C2c+6A77bZQErRRBcRkcLyp/RrAjtyXc/ybcutAdDAzBaY2WIzSynEfUVEJED8+SA3v08V8n68HAHUBzoD8UCamTX2876Y2UBgIEDt2rX9iCQiIhfCn5l+FlAr1/V4YGc+Yz5yzp12zm0BNpDzIuDPfXHOTXLOJTnnkuLi4gqTX0RECsGf0l8K1DezRDOLAnoD0/OM+RC4FsDMYsl5u2czMAu40cyqmFkV4EbfNhER8UCBb+84586Y2WByyjoceMU5t8bMRgDpzrnp/Kfc1wJngd845/YDmNkz5LxwAIxwzh0ojl9EREQKZoE47bcwkpKSXHp6utcxRESCipktc84lFTiupJW+mWUD2y7in4gF9hVRnKKkXIWjXIWjXIVTGnPVcc4V+KFoiSv9i2Vm6f682gWachWOchWOchVOKOfSgmsiIiFEpS8iEkJKY+lP8jrAeShX4ShX4ShX4YRsrlL3nr6IiJxfaZzpi4jIeQRl6Re0vr+ZRZvZu77bl5hZQgnJ1d/Mss1she/nVwHK9YqZ7TWzb89zu5nZGF/uVWbWsoTk6mxmh3Ptrz8GKFctM5tnZut83w8xLJ8xAd9nfuYK+D4zsxgz+9rMVvpy/W8+YwL+nPQzlyfPSd9jh5vZcjObkc9txbe/nHNB9UPOWcGbgMuBKGAl0CjPmIeBib7LvYF3S0iu/sA4D/ZZMtAS+PY8t3cDPiVngbw2wJISkqszMMOD/VUdaOm7XAHIyOe/ZcD3mZ+5Ar7PfPugvO9yJLAEaJNnjBfPSX9yefKc9D32Y8A7+f33Ks79FYwzfX/W9+8JvO67PA243syK9zvI/MvlCedcKvBzy1/0BN5wORYDlc2segnI5Qnn3C7n3De+y98D6/jpkuAB32d+5go43z446rsa6fvJ+2FhwJ+TfubyhJnFAzcD/zrPkGLbX8FY+v6s0f9/Y5xzZ4DDwCUlIBfAHb63A6aZWa18bvdCSf7eg7a+P88/NbOrAv3gvj+rW5AzS8zN0332M7nAg33me6tiBbCXnC9OOu/+CuBz0p9c4M1zchTwW+DceW4vtv0VjKXvzxr9fq3jX8T8ecyPgQTnXFNgDv95JfeaF/vLH9+Qc2p5M2AsOau5BoyZlQfeB4Y7547kvTmfuwRknxWQy5N95pw765xrTs7y6a0t5/s0cvNkf/mRK+DPSTPrDux1zi37uWH5bCuS/RWMpe/v+v61AMwsAqhE8b+NUGAu59x+59xJ39WXgFbFnMlffn3vQaA55478+Oe5c24mEGk5S3cXOzOLJKdY33bO/TufIZ7ss4JyebnPfI95CPiSn34tqhfPyQJzefScbA/0MLOt5LwNfJ2ZvZVnTLHtr2AsfX/W958O9PNd7gV84XyfiHiZK897vj3IeU+2JJgO3Os7IqUNcNg5t8vrUGZW7cf3Mc2sNTn/f90fgMc14GVgnXPu+fMMC/g+8yeXF/vMzOLMrLLvchngBmB9nmEBf076k8uL56Rz7nfOuXjnXAI5PfGFc+7uPMOKbX/583WJJYrzb33/l4E3zSyTnFfH3iUk11Az6wGc8eXqX9y5AMxsMjlHdcSaWRbwJ3I+1MI5NxGYSc7RKJnAceC+EpKrFzDIzM4APwC9A/DiDTkzsXuA1b73gwGeAmrnyubFPvMnlxf7rDrwupmFk/MiM9U5N8Pr56SfuTx5TuYnUPtLZ+SKiISQYHx7R0RELpBKX0QkhKj0RURCiEpfRCSEqPRFREKISl9EJISo9EVEQohKX0QkhPx/cAmNAFo3tZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 3)\n",
    "plt.subplot(gs1[0])\n",
    "plt.imshow(img_us_np[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(gs1[1])\n",
    "plt.imshow(img_gt_np[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(gs1[2])\n",
    "plt.imshow(img_us_rss[0,0,:,:].detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"us_max=\",img_us_np.max(),\"fs_max=\",img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "plt.subplot(gs1[0])\n",
    "plt.imshow(img_us_np[0,0,:,:].detach().cpu()*maxi.detach().cpu(),cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(gs1[1])\n",
    "plt.imshow(img_gt_np[0,0,:,:].detach().cpu()*maxi.detach().cpu(),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking on actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_tr = '/media/student1/RemovableVolume/calgary/Train/e14140s3_P52224.7.118.h5'\n",
    "with h5py.File(fname_tr, 'r') as data:\n",
    "\n",
    "    ksp = data['kspace'][()]\n",
    "    sens = data['sensitivity'][()]\n",
    "ksp.shape , sens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt_np = T.zero_filled_reconstruction(ksp)\n",
    "img_gt_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gt_np,cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replacing randomly initialized layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_model = '/media/student1/NewVolume/MR_Reconstruction/experiments/midl/varnet/12-channels/pretext/acc_5x/best_model.pt'\n",
    "model1  = build_model(args)\n",
    "_, model0,_ = load_model(pretext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "plt.subplot(gs1[0])\n",
    "out,out_stack,sens= model0(img_us,ksp_us,mask)\n",
    "plt.imshow(out[0,0,:,:].detach().cpu().numpy())\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(gs1[1])\n",
    "out1,out_stack1,sens1= model1(img_us,ksp_us,mask)\n",
    "plt.imshow(out1[0,0,:,:].detach().cpu().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_us_sens = T.combine_all_coils(img_us.squeeze(0),sens.squeeze(0)).unsqueeze(0)\n",
    "img_us_sens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "plt.subplot(gs1[0])\n",
    "out = model0.model_vs.conv_blocks[0](img_us_sens)\n",
    "plt.imshow(np.sqrt(out[0,:,:,0].detach().cpu().numpy()**2 + out[0,:,:,1].detach().cpu().numpy()**2))\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(gs1[1])\n",
    "out1 = model1.model_vs.conv_blocks[0](img_us_sens)\n",
    "plt.imshow(np.sqrt(out1[0,:,:,0].detach().cpu().numpy()**2 + out1[0,:,:,1].detach().cpu().numpy()**2))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the weights of model0\n",
    "model0.model_vs.conv_blocks[0] = model1.model_vs.conv_blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "plt.subplot(gs1[0])\n",
    "out = model0.model_vs.conv_blocks[0](img_us_sens)\n",
    "plt.imshow(np.sqrt(out[0,:,:,0].detach().cpu().numpy()**2 + out[0,:,:,1].detach().cpu().numpy()**2))\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(gs1[1])\n",
    "out1 = model1.model_vs.conv_blocks[0](img_us_sens)\n",
    "plt.imshow(np.sqrt(out1[0,:,:,0].detach().cpu().numpy()**2 + out1[0,:,:,1].detach().cpu().numpy()**2))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bck = 2\n",
    "for i in range(-bck,0):\n",
    "    print(\"i=\",i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import data.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/media/student1/RemovableVolume/calgary_new/Test/test_12_channel/Test-R=5/e15274s3_P20992.7.h5\"\n",
    "slice = 100\n",
    "with h5py.File(data_path, 'r') as data:\n",
    "\n",
    "    zf_kspace = data['kspace'][()]\n",
    "    mask_sampling = ~( np.abs(zf_kspace).sum( axis = (0, -1) ) == 0)\n",
    "    mask_np = 1.0*mask_sampling\n",
    "    ksp = zf_kspace[slice+50]\n",
    "\n",
    "\n",
    "ksp_cmplx = ksp[:,:,::2] + 1j*ksp[:,:,1::2]\n",
    "ksp_t = T.to_tensor(ksp_cmplx)\n",
    "ksp_us= ksp_t.permute(2,0,1,3)\n",
    "img_us = T.ifft2(ksp_us)\n",
    "img_us_np = T.root_sum_of_squares(T.complex_abs(T.ifft2(ksp_us)))\n",
    "img_us_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_path = '/media/student1/RemovableVolume/calgary_new/team_the_enchanted_v3/Track01/12-channel-R=5/e15274s3_P20992.7.h5'\n",
    "with h5py.File(recons_path, 'r') as data:\n",
    "\n",
    "    out = data['reconstruction'][()]\n",
    "print(\"out=\",out.shape)\n",
    "out = out[slice,0,:,:]\n",
    "# out.shape  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "plt.subplot(gs1[0])\n",
    "plt.imshow(img_us_np,cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(gs1[1])\n",
    "plt.imshow(out,cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_ksp = ksp_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_cmplx = ksp_us[:,:,:,:,0].detach() + 1j*ksp_us[:,:,:,:,1]\n",
    "ksp_cmplx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convdecoder setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numit = 25000\n",
    "LR = 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "def add_module(self, module):\n",
    "    self.add_module(str(len(self) + 1), module)\n",
    "\n",
    "torch.nn.Module.add = add_module\n",
    "\n",
    "class conv_model(nn.Module):\n",
    "    def __init__(self, num_layers, strides, num_channels, num_output_channels, hidden_size, upsample_mode, act_fun,sig=None, bn_affine=True, skips=False,intermeds=None,bias=False,need_lin_comb=False,need_last=False,kernel_size=3):\n",
    "        super(conv_model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.upsample_mode = upsample_mode\n",
    "        self.act_fun = act_fun\n",
    "        self.sig= sig\n",
    "        self.skips = skips\n",
    "        self.intermeds = intermeds\n",
    "        self.layer_inds = [] # record index of the layers that generate output in the sequential mode (after each BatchNorm)\n",
    "        self.combinations = None # this holds input of the last layer which is upsampled versions of previous layers\n",
    "        \n",
    "        cntr = 1\n",
    "        net1 = nn.Sequential()\n",
    "        for i in range(num_layers-1):\n",
    "            \n",
    "            net1.add(nn.Upsample(size=hidden_size[i], mode=upsample_mode))#,align_corners=True))\n",
    "            cntr += 1\n",
    "            \n",
    "            conv = nn.Conv2d(num_channels, num_channels, kernel_size, strides[i], padding=(kernel_size-1)//2, bias=bias)\n",
    "            net1.add(conv)\n",
    "            cntr += 1\n",
    "            \n",
    "            #net1.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
    "            net1.add(act_fun)\n",
    "            cntr += 1\n",
    "            \n",
    "            if need_lin_comb:\n",
    "                net1.add(nn.BatchNorm2d( num_channels, affine=bn_affine)) \n",
    "                #net1.add(act_fun)\n",
    "                cntr += 1\n",
    "\n",
    "                net1.add(nn.Conv2d(num_channels, num_channels, 1, 1, padding=0, bias=bias))\n",
    "                cntr += 1\n",
    "\n",
    "                #net1.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
    "                net1.add(act_fun)\n",
    "                cntr += 1\n",
    "            \n",
    "            #net1.add(act_fun)\n",
    "            net1.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
    "            if i != num_layers - 2: # penultimate layer will automatically be concatenated if skip connection option is chosen\n",
    "                self.layer_inds.append(cntr)\n",
    "            cntr += 1\n",
    "\n",
    "        net2 = nn.Sequential()\n",
    "        \n",
    "        nic = num_channels\n",
    "        if skips:\n",
    "            nic = num_channels*( sum(intermeds)+1 )\n",
    "        \n",
    "        if need_last:\n",
    "            net2.add( nn.Conv2d(nic, num_channels, kernel_size, strides[i], padding=(kernel_size-1)//2, bias=bias) )\n",
    "            net2.add(act_fun)\n",
    "            net2.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
    "            nic = num_channels\n",
    "            \n",
    "        net2.add(nn.Conv2d(nic, num_output_channels, 1, 1, padding=0, bias=bias))\n",
    "        \n",
    "        if sig is not None:\n",
    "            net2.add(self.sig)\n",
    "        \n",
    "        self.net1 = net1 \n",
    "        self.net2 = net2\n",
    "        \n",
    "    def forward(self, x, scale_out=1):\n",
    "        out1 = self.net1(x)\n",
    "        if self.skips:\n",
    "            intermed_outs = []\n",
    "            for i,c in enumerate(self.net1):\n",
    "                if i+1 in self.layer_inds:\n",
    "                    f = self.net1[:i+1]\n",
    "                    intermed_outs.append(f(x))\n",
    "            intermed_outs = [intermed_outs[i] for i in range(len(intermed_outs)) if self.intermeds[i]]\n",
    "            intermed_outs = [self.up_sample(io) for io in intermed_outs]\n",
    "            out1 = torch.cat(intermed_outs+[out1],1)\n",
    "        self.combinations = copy(out1)\n",
    "        out2 = self.net2(out1)\n",
    "        return out2*scale_out\n",
    "    def up_sample(self,img):\n",
    "        samp_block = nn.Upsample(size=self.hidden_size[-1], mode=self.upsample_mode)#,align_corners=True)\n",
    "        img = samp_block(img)\n",
    "        return img\n",
    "\n",
    "def convdecoder(\n",
    "        out_size = [256,256],\n",
    "        in_size = [16,16],\n",
    "        num_output_channels=2,\n",
    "        num_layers=6,\n",
    "        strides=[1]*6,\n",
    "        num_channels=64,\n",
    "        need_sigmoid=True, \n",
    "        pad='reflection', \n",
    "        upsample_mode='bilinear', \n",
    "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
    "        bn_before_act = False,\n",
    "        bn_affine = True,\n",
    "        skips = True,\n",
    "        intermeds=None,\n",
    "        nonlin_scales=False,\n",
    "        bias=False,\n",
    "        need_lin_comb=False,\n",
    "        need_last=False,\n",
    "        kernel_size=3,\n",
    "        ):\n",
    "    \n",
    "    \n",
    "    scale_x,scale_y = (out_size[0]/in_size[0])**(1./(num_layers-1)), (out_size[1]/in_size[1])**(1./(num_layers-1))\n",
    "    if nonlin_scales:\n",
    "        xscales = np.ceil( np.linspace(scale_x * in_size[0],out_size[0],num_layers-1) )\n",
    "        yscales = np.ceil( np.linspace(scale_y * in_size[1],out_size[1],num_layers-1) )\n",
    "        hidden_size = [(int(x),int(y)) for (x,y) in zip(xscales,yscales)]\n",
    "    else:\n",
    "        hidden_size = [(int(np.ceil(scale_x**n * in_size[0])),\n",
    "                        int(np.ceil(scale_y**n * in_size[1]))) for n in range(1, (num_layers-1))] + [out_size]\n",
    "    print(hidden_size)\n",
    "    if need_sigmoid:\n",
    "        sig = nn.Sigmoid()\n",
    "        #sig = nn.Tanh()\n",
    "        #sig = nn.Softmax()\n",
    "    else:\n",
    "        sig = None\n",
    "    \n",
    "    model = conv_model(num_layers, strides, num_channels, num_output_channels, hidden_size,\n",
    "                         upsample_mode=upsample_mode, \n",
    "                         act_fun=act_fun,\n",
    "                         sig=sig,\n",
    "                         bn_affine=bn_affine,\n",
    "                         skips=skips,\n",
    "                         intermeds=intermeds,\n",
    "                         bias=bias,\n",
    "                         need_lin_comb=need_lin_comb,\n",
    "                         need_last = need_last,\n",
    "                         kernel_size=kernel_size,)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_param(net):\n",
    "    s = sum([np.prod(list(p.size())) for p in net.parameters()]);\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.randn(15,2,320,320)\n",
    "slice_ksp = x\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor\n",
    "output_depth = slice_ksp.shape[0]*2\n",
    "out_size = slice_ksp.shape\n",
    "print(\"out_size\",out_size)\n",
    "num_channels = 160 #256\n",
    "num_layers = 7\n",
    "strides = [1]*(num_layers-1)\n",
    "in_size = [8,4]\n",
    "kernel_size = 3\n",
    "parnet = convdecoder(out_size,in_size,output_depth,\n",
    "                     num_layers,strides,num_channels, act_fun = nn.ReLU(),\n",
    "                     skips=False,need_sigmoid=False,bias=False, need_last = True,\n",
    "                     kernel_size=kernel_size,upsample_mode=\"nearest\").type(dtype)\n",
    "print(num_param(parnet))\n",
    "parnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(15,2,320,320)\n",
    "y = parnet(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 40\n",
    "slice = 50 + index\n",
    "fname = '/media/student1/RemovableVolume/calgary_new/exp1/Track01/12-channel-R=5/e15790s3_P01536.7.h5'\n",
    "with h5py.File(fname, 'r') as data:\n",
    "\n",
    "    recons = data['reconstruction'][()]\n",
    "recons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(recons[index,0,:,:],cmap='gray')\n",
    "plt.colorbar()\n",
    "print(recons.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_ori = '/media/student1/RemovableVolume/calgary_new/Test/test_12_channel/Test-R=5/e15790s3_P01536.7.h5'\n",
    "with h5py.File(fname_ori, 'r') as data:\n",
    "\n",
    "            kspace = data['kspace'][slice]\n",
    "            sr = 0.85\n",
    "            Nz = kspace.shape[1]\n",
    "            Nz_sampled = int(np.ceil(Nz*sr))\n",
    "\n",
    "            kspace[:,Nz_sampled:,:] = 0\n",
    "            ksp_cmplx = kspace[:,:,::2] + 1j*kspace[:,:,1::2]\n",
    "            \n",
    "ksp_cmplx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_t = T.to_tensor(ksp_cmplx)\n",
    "ksp_t = ksp_t.permute(2,0,1,3)\n",
    "ksp_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt_np = T.root_sum_of_squares(T.complex_abs(T.ifft2(ksp_t)))\n",
    "img_gt_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gt_np,cmap='gray')\n",
    "plt.colorbar()\n",
    "print(img_gt_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_wise_ifft(zero_filled_kspace):\n",
    "    \"\"\"\n",
    "    Computes the iFFT across channels of multi-channel k-space data. The input is expected to be a complex numpy array.\n",
    "    \"\"\"\n",
    "    return np.fft.ifft2(zero_filled_kspace, axes = (0,1))\n",
    "    \n",
    "    \n",
    "\n",
    "def sum_of_squares(img_channels):\n",
    "    \"\"\"\n",
    "    Combines complex channels with square root sum of squares. The channels are the last dimension (i.e., -1) of the input array.\n",
    "    \"\"\"\n",
    "    return np.sqrt((np.abs(img_channels)**2).sum(axis = -1))\n",
    "    return sos    \n",
    "\n",
    "def zero_filled_reconstruction(zero_filled_kspace):\n",
    "    \"\"\"\n",
    "    Zero-filled reconstruction of multi-channel MR images. The input is the zero-filled k-space. The channels\n",
    "    are the last dimension of the array. The input may be either complex-valued or alternate between real and imaginary channels \n",
    "    in the last array dimension.\n",
    "    \"\"\"\n",
    "    if not np.iscomplexobj(zero_filled_kspace):\n",
    "        zero_filled_kspace = zero_filled_kspace[:,:,:,::2] + 1j*zero_filled_kspace[:,:,:,1::2] #convert real-imag to complex data\n",
    "    \n",
    "    img_gt_np = sum_of_squares(channel_wise_ifft(zero_filled_kspace))\n",
    "#     img_gt_np = torch.from_numpy(img_gt_np)\n",
    "\n",
    "    \n",
    "    return img_gt_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np = T.zero_filled_reconstruction(ksp_cmplx)\n",
    "img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_np,cmap='gray')\n",
    "\n",
    "plt.colorbar()\n",
    "print(img_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname_ori = '/media/student1/RemovableVolume/calgary/Train/e16972s3_P31232.7.99.h5'\n",
    "with h5py.File(fname_ori, 'r') as data:\n",
    "    ksp_gt_np = data['kspace'][()]\n",
    "    sens = data['sensitivity'][()]\n",
    "ksp_gt_np.shape\n",
    "ksp_gt_t = T.to_tensor(ksp_gt_np)\n",
    "ksp_t = ksp_gt_t.permute(2,0,1,3)\n",
    "ksp_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_t = T.to_tensor(sens)\n",
    "sens_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.abs(ksp_gt_np[:,:,0])+ 1e-8))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft2(img_t):\n",
    "    \"\"\"\n",
    "    img_ch has shape = [ch,218,180,2] in torch tensor format\n",
    "    Computes the iFFT across channels of multi-channel k-space data.\n",
    "    Returns channel wise ifft in torch format.\n",
    "    \"\"\"\n",
    "    # print(\"ZF\",zero_filled_kspace.shape)\n",
    "    img_np = img_t[:,:,:,0].numpy() + 1j*img_t[:,:,:,1].numpy()\n",
    "    img_np = img_np.transpose(1,2,0)\n",
    "    \n",
    "    ksp_np = np.fft.fft2(img_np, axes = (0,1))\n",
    "    \n",
    "    ksp_t = T.to_tensor(ksp_np)\n",
    "    return ksp_t.permute(2,0,1,3)\n",
    "\n",
    "\n",
    "def ifft2(ksp_t):\n",
    "    \"\"\"\n",
    "    ksp_ch has shape = [ch,218,180,2] in torch tensor format\n",
    "    Computes the iFFT across channels of multi-channel k-space data.\n",
    "    Returns channel wise ifft in torch format.\n",
    "    \"\"\"\n",
    "    # print(\"ZF\",zero_filled_kspace.shape)\n",
    "    ksp_np = ksp_t[:,:,:,0].numpy() + 1j*ksp_t[:,:,:,1].numpy()\n",
    "    ksp_np = ksp_np.transpose(1,2,0)\n",
    "    \n",
    "    img_np = np.fft.ifft2(ksp_np, axes = (0,1))\n",
    "    \n",
    "    img_t = T.to_tensor(img_np)\n",
    "    return img_t.permute(2,0,1,3)\n",
    "\n",
    "\n",
    "def root_sum_of_squares(data, dim=0):\n",
    "    \"\"\"\n",
    "    Compute the Root Sum of Squares (RSS) transform along a given dimension of a tensor.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): The input tensor\n",
    "        dim (int): The dimensions along which to apply the RSS transform\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The RSS value\n",
    "    \"\"\"\n",
    "    return torch.sqrt((data ** 2).sum(dim))\n",
    "\n",
    "\n",
    "def complex_abs(data):\n",
    "    \"\"\"\n",
    "    Compute the absolute value of a complex valued input tensor.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): A complex valued tensor, where the size of the final dimension\n",
    "            should be 2.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Absolute value of data\n",
    "    \"\"\"\n",
    "    assert data.size(-1) == 2\n",
    "    return (data ** 2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_t_np = ksp_t.numpy()\n",
    "ksp_t_cmplx = ksp_t_np[:,:,:,0] + 1j*ksp_t_np[:,:,:,1]\n",
    "ksp_gt_np = ksp_t_cmplx.transpose(1,2,0)\n",
    "ksp_gt_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt_np = np.fft.ifft2(ksp_gt_np, axes = (0,1))\n",
    "img_gt_np.shape\n",
    "plt.imshow(np.abs(img_gt_np[:,:,0]),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ifft2(ksp_t)\n",
    "img.shape\n",
    "# plt.imshow(torch.sqrt(img[0,:,:,0]**2 + img[0,:,:,1]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rss = root_sum_of_squares(complex_abs(img))\n",
    "img_rss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rss,cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np = T.zero_filled_reconstruction(ksp_gt_np)\n",
    "img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_np,cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp = fft2(img)\n",
    "ksp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.log(torch.sqrt(ksp[0,:,:,0]**2 + ksp[0,:,:,1]**2) + 1e-8))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def perform(self,out_img_cmplx,ksp,sens,mask ):\n",
    "        \n",
    "        x = T.complex_multiply(out_img_cmplx[...,0].unsqueeze(1), out_img_cmplx[...,1].unsqueeze(1), sens[...,0], sens[...,1])\n",
    "    \n",
    "        k = (torch.fft(x, 2, normalized=True)).squeeze(1)\n",
    "        k_shift = T.ifftshift(k, dim=(-3,-2))\n",
    "\n",
    "        \n",
    "        sr = 0.85\n",
    "        Nz = k_shift.shape[-2] \n",
    "        Nz_sampled = int(np.ceil(Nz*sr))\n",
    "        k_shift[:,:,:,Nz_sampled:,:] = 0\n",
    "        \n",
    "        v = self.noise_lvl\n",
    "\n",
    "        if v is not None: # noisy case\n",
    "            # out = (1 - mask) * k + mask * (k + v * k0) / (1 + v)\n",
    "            out = (1 - mask) * k_shift + mask * (v * k_shift + (1 - v) * ksp) \n",
    "        \n",
    "        else:\n",
    "           \n",
    "            out = (1 - mask) * k_shift + mask * ksp\n",
    "            \n",
    "        \n",
    "        x = torch.ifft(out, 2, normalized=True)\n",
    "    \n",
    "        Sx = T.complex_multiply(x[...,0], x[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "        \n",
    "        Ss = T.complex_multiply(sens[...,0], sens[...,1], sens[...,0],-sens[...,1]).sum(dim=1)\n",
    "     \n",
    "        return Sx, Ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ifft2(ksp_t).unsqueeze(0)\n",
    "img.shape , sens_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = T.combine_all_coils(img.squeeze(0).float(),sens_t.float()).unsqueeze(0)\n",
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens2 = sens_t.unsqueeze(0)\n",
    "sens2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.complex_multiply(img2[...,0].unsqueeze(1), img2[...,1].unsqueeze(1), sens2[...,0], sens2[...,1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.sqrt(img2[0,:,:,0]**2 + img2[0,:,:,1]**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.sqrt(x[0,0,:,:,0]**2 + x[0,0,:,:,1]**2),cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
